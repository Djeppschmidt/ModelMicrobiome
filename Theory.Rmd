---
title: "Standardized Approaches to Microbial Metabarcoding Studies"
author: "Dietrich Epp Schmidt"
date: "7/25/2019"
output: html_document
---

## introduction
For some time there has been contentious debate over the appropriate data handling techniques for microbial sequence data. The center of the controversy is the question of whether we should or should not rarefy our samples. In this case, rarefaction means subsampling each sample to a certain threshold. Typically, the practitioner will determine an arbitrary minimum count and rarefy all samples down to this count. This technique is employed to adress the lack of uniform sampling effort that is inherent in sequence data (CITATION). It should be pointed out here that subsampling sequences to an equal number of sequences is not in fact normalizing sampling effort. McMurdie and Holmes argued in 2014 that no sequences should be omitted for the purpose of normalizing sampling effort. Their argument essentially is that to do causes us to lose the power to detect taxa that respond, and increased in false positives. Later, Weiss et al countered that their method unfairly handicapped rarefied datasets in their modeling. The center of the dispute was in how the mock community was constructed, and scored. McCmurdie and Holmes had manually increased the abundance of certain taxa in the dataset. They only counted those that they had manipulated as being true positives. But if one taxon should increase in abundance, then as a proportion all other taxa will decrease. These are true effects in the sense that the relative abundance of each taxon is actually changing within the dataset. McMurdie and Holmes, however, scored those detections as false positives and found that rarefied data had a much higher probability of detecting such false positives. Weiss et all argued that in fact these were true positives, suggesting that rarefaction actually increased the sensitivity of the differential abundance analysis. They proposed using a mock community where manipulated taxa are reciprocally balanced such that they do not affect the relative abundance of any other taxon (if one taxon is increased by 10, another is decreased by 10 for balance). This differential abundance test showing that rarefaction did sometimes improve true positive detection, depending on the context. It should be pointed out here that strictly speaking, this type of behavior (i.e. perfectly balanced differences in taxon abundance) does not occure in nature.

What is perhaps most curious about this debate is what is not addressed: the underlying reason that ecologists seek to rarefy data. The concept of effort in sampling is quite literally a representation of physical effort in much of macro-ecology. It seeks to ensure that, for example, the dimensions of area surveyed in each sampling location of a study are equal so that the results are directly comparable. In sequencing studies, effort cannot be controled a priori either physically or procedurally by the scientist because the sequencing machine acts much like a random number generator in determining how many counts (often interpreted as effort) is devoted to each sample. But counts themselves are not intrinsically a measure of effort. If population A has twice the density of organisms than population B, then if samples of both are represented by the same number of sequences, then twice the effort has been expended on sampling population B compared to population A. Effort per unit sampled is important to normalize because it provides a standardization that allows the scientist to infer the density of the organisms. Therefore, to control effort is to normalize for organismal density in the real world. This key observation is lost in the discussion as none of the parties (and none of the softwares employed) include a standard protocol for normalizing for population density across samples. This is because the major publicly available softwares in this realm (particularly DESeq2, EdgeR, and Limma) were developed to determine differential expression of genes within organisms - not the differential abundance of organisms in the environment. They were designed to work with either with RNA-seq data, and often are expansions of software originally developed for micro-array analysis. In this data context, the overall abundance of RNA in the cell is rarely, if ever, an important factor to consider. Since gene expression is highly interdependent within an organism, expression data is best understood as a distribution where autocorrelation of the sequence counts is assumed. Therefore, all of these algorithms include normalization protocol for sample-wise sequencing depth within the GLM. However, for microbiome work the density of the overall community is of paramount importance. The diversity of metabolic strategies is such that groups of microbes may be essentially independent in their growth, each either relying on or being limited by different substrates. If one group becomes more abundant while the other remains at the same abundance level, it is impossible to parse whether one grew or the other died off simply using distributional (or proportional) data. In order to accurately infer the environmental drivers of each taxon, the practicioner needs to model a population density correction into the GLM. Thus, to understand how the environment shapes any microbial community, there must be an independent measure of overall community abundance. The power of external normalization has recently been demonstrated as a XYZ et. al published a paper where they were able to achieve nearly quantitative estimation of taxon abundance using QPCR as an external measure of total bacterial density. 

From the ecological perspective, much of the modeling for expression data has been done backwards. Typically, the modeler generates a random base dataset, manipulate part of it to generate a "treatment effect," then tests if the algorithm accurately identifies the manipulation. This does not allow the modeler to test the algorithm's ability to infer the state of an original population; in essence this is just a test of the algorithm's ability to infer the state of the sample. In order to benchmark the algorithm's ability to infer the population parameters, we must make a model population, sample from the model population, and then supply the algorithm with the sample data and determine its accuracy in predicting the actual state of the population. None of the popular algorithms employed for differential abundance testing have been benchmarked in this way. It also has the advantage that it eliminates subjectivity in interpreting the results because there is a modeled population in the simulation. There can be no quibble over the proper scoring for the benchmark.

Fragments:
XYZ et al's data demonstrates that highly abundant taxa are easy to model using an external... This is because normalizing the distribution to the density will
Rarefaction is often misapplied in The advantage of rarefaction is that it allows us to normalize the sequence distributio

##Methods and Results

First we use a simplistic community model framework designed to elucidate explicitly the theoretical weaknesses of different preprossessing and statistical approaches. Then we present a flexible modeling platform that allows us to construct dynamic and nuanced community models to test the bounds of the inferential statistical software.

![Analysis Workflow](images/week3/silly-dog.png)
# Model Community 1
Construct a model population. In this case we used the fibonacci sequence as a base for taxon abundance curves. We create several different detection scenarios for how the taxa could respond to the environment. Here the only environmental data is total population for each sample.

```{r}
library(phyloseq)

fib1<-c(1,1,2,3,5,8,13,21,34,55,89,144,233,377,610) #1596 (Reference conditions)
fib2<-fib1*2 #3192 (wrt ref: all taxa increase) ;(expected false: all the same)
fib3<-c(1,1,2,3,8,5,13,21,34,55,89,144,377,233,610) # (wrt ref: 5,13 increases, 6,14 decreases); expected false: NA
fib4<-fib3*2 # (wrt ref: all taxa increase); expected false(5,13 increases, 6,14 decreases)
fib5<-c(1,1,2,3,8,8,13,21,34,55,89,233,233,377,610) # a (wrt ref: 5,12 increases) ;expected false(NA)
fib6<-fib5*2 # (wrt ref: all taxa increase); expected false(5,12 increases)
fib7<-c(1,1,2,3,5,8,8,21,34,55,89,144,233,377,377) # (wrt ref: 7,15 decreases); expected false(NA)
fib8<-fib7*2 # (wrt ref: all taxa increase) ; expected false(7,15 decreases)
fib9<-c(1,1,2,0,5,0,13,21,34,55,89,144,0,377,610) # identify zeros; expected false(NA)
fib10<-fib9*2 # (wrt ref: 4,6,13 decrease, all others increase); expected false(4,6,13 decrease)
fib11<-c(1,1,2,3,5,8,13,21,34,55,89,144,466,754,1220) # (wrt ref: only top 3 increase) ; expected false(bottom 12 decrease)
fib12<-c(2,2,4,6,10,16,26,42,68,11,178,288,233,377,610) # (wrt ref: all increase except top 3 stay same); expected false(top 3 decrease)

#now let's make a community where the majority of taxa are only in one site
#first 15 are ubiquitous
fib13<-c(5,10,100,5,10,20,1,1,1,280,124,100,790,540,420,233,377,610,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0)
fib14<-c(5,10,100,0,0,0,540,420,1,1,1,280,5,10,20,0,0,0,0,233,377,610,0,0,0,0,0,0,0,0,0,0,0,0,0)
fib15<-c(5,10,100,0,0,0,540,420,1,1,1,280,5,540,420,0,0,0,0,0,0,0,0,0,233,377,610,0,0,0,0,0,0,0,0)
fib16<-c(5,10,100,0,0,0,540,420,1,1,1,280,5,540,420,0,0,0,0,0,0,0,0,0,0,0,0,233,377,610,0,0,0,0,0)
fib17<-c(5,rep(1,5),0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,89,144,466,233,377,610,0,0,0,0,500,50,100,200)

comm<-data.frame(fib1,fib2,fib3,fib4,fib5,fib6,fib7,fib8,fib9,fib10,fib11,fib12)
rownames(comm)<-paste(rep("sp",15), c(1:15), sep=".")

comm2<-data.frame(fib13, fib14, fib15, fib16, fib17)
rownames(comm2)<-paste(rep("sp",35), c(1:35), sep=".")
```

Now let's sample from our defined populations, and construct our sampled phyloseq object. This function is meant to simulate the sequencing machine. For this, we employ a function that samples from our population with replacement. Replacement is important because in almost all metabarcoding protocol there is amplification that creates artificial copies that follow the distribution, but not total number. In effect, sequencing is sampling with replacement. This function models sequencing also by assigning random total sample values and (unless otherwise specified) generates a random total number of sequences per sample with a mean value of 250 sequences and a variance of 75 sequences.

```{r}

make.table<-function(comm, r){ 
  
  m<-as.data.frame(t(table(sample(rownames(comm),rnorm(1, 250, 75), replace=T, prob=comm[,1]/sum(comm[,1])))))
   m<-m[,colnames(m)!="Var1"]
   colnames(m)[colnames(m)=="Freq"]<-paste("site", 1, r, sep=".")
    m2<-as.data.frame(t(table(sample(rownames(comm),rnorm(1, 250, 75), replace=T, prob=comm[,2]/sum(comm[,2])))))
   m<-merge(m, m2, by="Var2", all=T)
    m<-m[,colnames(m)!="Var1"]
    colnames(m)[colnames(m)=="Freq"]<-paste("site", 2, r, sep=".")
    for(i in 3:ncol(comm)){
     a<-as.data.frame(t(table(sample(rownames(comm),rnorm(1, 250, 75), replace=T, prob=comm[,i]/sum(comm[,i])))))
     a<-a[,colnames(a)!="Var1"]
     m<-merge(m,a, by="Var2", all=T)
      m<-m[,colnames(m)!="Var1"]
      colnames(m)[colnames(m)=="Freq"]<-paste("site", i, r, sep=".")
      
    }
    #colnames(m)<-c("Var1", paste0("site",c(1:12), r, sep="."))
      #names(m)[names(m)=="Var2"]<-paste0("Sample", r,)
      rownames(m)<-m$Var2
      m
    }

model.rarefy<-function(comm, rep){
 a<-make.table(comm, r=1)
 #a<-a[,colnames(a)!="Var1"]
 for(r in 2:rep){
   b<-make.table(comm, r)
   a<-merge(a,b,by="Var2", all=T)
   a<-a[,colnames(a)!="Var1"]}
   rownames(a)<-a$Var2
   a<-a[,colnames(a)!="Var2"]
   a[is.na(a)] <- 0
   a
 }


# add CSS!!

library(metagenomeSeq)


model1.otu<-model.rarefy(comm, 3) # works
s.order1<-c("site.1.1", "site.1.2", "site.1.3", "site.2.1", "site.2.2", "site.2.3", "site.3.1", "site.3.2", "site.3.3", "site.4.1", "site.4.2", "site.4.3", "site.5.1","site.5.2","site.5.3", "site.6.1","site.6.2","site.6.3", "site.7.1","site.7.2","site.7.3", "site.8.1","site.8.2","site.8.3", "site.9.1","site.9.2","site.9.3", "site.10.1","site.10.2","site.10.3", "site.11.1","site.11.2","site.11.3", "site.12.1","site.12.2","site.12.3")
model1.otu<-model1.otu[,s.order1]


 
#model2.otu<-model.rarefy(comm=comm2, 5) # works
#s.order2<-c("site.1.1", "site.1.2", "site.1.3", "site.1.4", "site.1.5", "site.2.1", "site.2.2", "site.2.3", "site.2.4","site.2.5","site.3.1", "site.3.2", "site.3.3","site.3.4","site.3.5", "site.4.1", "site.4.2", "site.4.3","site.4.4","site.4.5", "site.5.1","site.5.2","site.5.3", "site.5.4","site.5.5")
#model2.otu<-model2.otu[,s.order2]

# construct the metadata
meta1<-data.frame("Factor" = as.factor(c(rep("one",3), rep("two",3),rep("three",3),rep("four",3), rep("five",3), rep("six",3),rep("seven",3),rep("eight",3),rep("nine",3),rep("ten",3),rep("eleven",3),rep("twelve",3))), "Sample" = c("site.1.1", "site.1.2", "site.1.3", "site.2.1", "site.2.2", "site.2.3", "site.3.1", "site.3.2", "site.3.3", "site.4.1", "site.4.2", "site.4.3", "site.5.1","site.5.2","site.5.3", "site.6.1","site.6.2","site.6.3", "site.7.1","site.7.2","site.7.3", "site.8.1","site.8.2","site.8.3", "site.9.1","site.9.2","site.9.3", "site.10.1","site.10.2","site.10.3", "site.11.1","site.11.2","site.11.3", "site.12.1","site.12.2","site.12.3"), "Density"=c(rep(sum(fib1), 3),rep(sum(fib2), 3),rep(sum(fib3), 3),rep(sum(fib4), 3),rep(sum(fib5), 3),rep(sum(fib6), 3),rep(sum(fib7), 3),rep(sum(fib8), 3),rep(sum(fib9), 3),rep(sum(fib10), 3),rep(sum(fib11), 3),rep(sum(fib12), 3)))
rownames(meta1)<-meta1$Sample
model1.ps<-phyloseq(otu_table(model1.otu, taxa_are_rows = T), sample_data(meta1))
sample_data(model1.ps)$Total_abundance<-sample_sums(model1.ps)
sample_data(model1.ps)$DensityF.model1<-sample_data(model1.ps)$Density/mean(sample_data(model1.ps)$Density)


meta2<-data.frame("Factor" = as.factor(c(rep("one",5), rep("two",5),rep("three",5),rep("four",5), rep("five",5))), "Sample" = c("site.1.1", "site.1.2", "site.1.3", "site.1.4", "site.1.5", "site.2.1", "site.2.2", "site.2.3", "site.2.4","site.2.5","site.3.1", "site.3.2", "site.3.3","site.3.4","site.3.5", "site.4.1", "site.4.2", "site.4.3","site.4.4","site.4.5", "site.5.1","site.5.2","site.5.3", "site.5.4","site.5.5"), "Density"=c(rep(sum(fib13), 5),rep(sum(fib14), 5),rep(sum(fib15), 5),rep(sum(fib16), 5),rep(sum(fib17), 5)))
rownames(meta2)<-meta2$Sample
model2.ps<-phyloseq(otu_table(model2.otu, taxa_are_rows = T), sample_data(meta2))
sample_data(model2.ps)$Total_abundance<-sample_sums(model2.ps)
sample_data(model2.ps)$DensityF.model2<-sample_data(model2.ps)$Density/mean(sample_data(model2.ps)$Density)


saveRDS(model.ps, "~/Documents/GitHub/ModelMicrobiome/ModelPS.RDS")
?phyloseq::subset_samples
```
There are several philosophies about how to normalize the sample data. Some say not to do any normalization, to leave counts as they are (method=untouched); some say that the sequence counts should be variance stabilized- there are several different methods (method=deseqVST and limmaVST); some say that the data should be rarefied to an even sampling depth (method=evenRarefied); some say that we should rarefy to depths that are proportional to an independent measure of overall population size (method=proportionalRarefied); and finally some say that we should simply scale the sample distributions to an independent measure of population size (method=scaled). We do all of these for comparison. We will simulate QPCR of our target gene using the sums of the modeled population. This will be a vector called (Density)

```{r}

make.rarefy2<-function(x, level){
  require(phyloseq)
  require(vegan)
  
  sample_data(x)$adj<-level
  
  if (length(level)==1){
     p<-prune_samples(sample_sums(x)>level, x) # define samples we want to keep, discard rest
  
  if (nsamples(x)>nsamples(p)){warning(as.character(nsamples(x)-nsamples(p)), " samples have been removed because they are lower than rarefaction limit")}
     
  r<-as.data.frame(as.matrix(otu_table(p)))
  meta<-sample_data(p)
  rr<-rrarefy(t(r), meta$adj)
  ps<-phyloseq(otu_table(t(rr), taxa_are_rows = T), sample_data(meta))
  ps} else {
    
     p<-prune_samples(sample_sums(x)>level, x)
  if (nsamples(x)>nsamples(p)){warning(as.character(nsamples(x)-nsamples(p)), " samples have been removed because they are lower than rarefaction limit")}
    
    r<-as.data.frame(as.matrix(otu_table(p)))
  meta<-sample_data(p)
  rr<-rrarefy(t(r), meta$adj)
  ps<-phyloseq(otu_table(t(rr), taxa_are_rows = T), sample_data(meta))
  ps
  }
}

make.scaled2<-function(ps, val, scale){
  scaled<-data.frame(mapply(`*`, data.frame(as.matrix(otu_table(transform_sample_counts(ps, function(x) x/sum(x))))), scale * val))# sample_data(ps)$val))
  names<-rownames(data.frame(as.matrix(otu_table(ps))))
  rownames(scaled)<-names
  scaled<-round(scaled)

  p2<-ps
  otu_table(p2)<- otu_table(scaled, taxa_are_rows=T)
  p2
}

make.rarefy1<-function(x, level){
  require(phyloseq)
  require(vegan)
  
  sample_data(x)$adj<-level
  
  if (length(level)==1){
     p<-prune_samples(sample_sums(x)>level, x) # define samples we want to keep, discard rest
  
  if (nsamples(x)>nsamples(p)){warning(as.character(nsamples(x)-nsamples(p)), " samples have been removed because they are lower than rarefaction limit")}
     
  r<-as.matrix(otu_table(p))
  meta<-sample_data(p)
  rr<-rrarefy(r, meta$adj)
  ps<-phyloseq(otu_table(t(rr), taxa_are_rows = T), sample_data(meta))
  ps} else {
    
     p<-prune_samples(sample_sums(x)>level, x)
  if (nsamples(x)>nsamples(p)){warning(as.character(nsamples(x)-nsamples(p)), " samples have been removed because they are lower than rarefaction limit")}
    
    r<-as.matrix(otu_table(p))
  meta<-sample_data(p)
  rr<-rrarefy(r, meta$adj)
  ps<-phyloseq(otu_table(t(rr), taxa_are_rows = T), sample_data(meta))
  ps
  }
}

make.scaled1<-function(ps, val, scale){
  scaled<-data.frame(mapply(`*`, data.frame(as.matrix(otu_table(transform_sample_counts(ps, function(x) x/sum(x))))), scale * val))# sample_data(ps)$val))
  names<-rownames(data.frame(as.matrix(otu_table(ps))))
  rownames(scaled)<-names
  scaled<-round(scaled)

  p2<-ps
  otu_table(p2)<- otu_table(scaled, taxa_are_rows=T)
  p2
}

# untouched ####
untouched<-model1.ps

# deseqVST ####
gm_mean = function(x, na.rm=TRUE){
  exp(sum(log(x[x > 0]), na.rm=na.rm) / length(x))
} # relative abundance

make.deseqVST<-function(ps, Factor, l=1){
r<-phyloseq_to_deseq2(ps, ~Factor)
geoMeans = apply(counts(r), 1, gm_mean)
dds = estimateSizeFactors(r, geoMeans = geoMeans)
#dds<-DESeqDataSetFromMatrix(r, sample_data(ps), design=~Factor)
#dds = estimateSizeFactors(dds)
if (l==1){dds = estimateDispersions(dds)} else {
dds <- estimateDispersionsGeneEst(dds)
 dispersions(dds) <- mcols(dds)$dispGeneEst
  }
vst = getVarianceStabilizedData(dds)
deseqVST<-ps
otu_table(deseqVST) <- otu_table(vst, taxa_are_rows = TRUE)
deseqVST
}
# LimmaVST ###

make.limmaVST<-function(ps, Factor){
  require(phyloseq)
  #ps<-filter_taxa(ps, function(x) sum(x)>0, T)
  counts<-as.data.frame(as.matrix(otu_table(ps)))
  factors<-unlist(sample_data(ps)[,Factor])
  design<-model.matrix(~factors)
  dge <- DGEList(counts=counts)
  dge <- calcNormFactors(dge) #what happens if we don't do this step?
  v<-voom(dge, design, plot=F)
  LimmaVST<-ps
  otu_table(LimmaVST)<-otu_table(v$E, taxa_are_rows = T)
  LimmaVST
}


```

Let's now run the functions to get all the different combinations of preprocessing...


```{r}

# evenRarefied ####
model1.eRare<-make.rarefy2(model1.ps, 100)  
#model2.eRare<-make.rarefy2(model2.ps, 100)


# proportionalRarefied ####
model1.pRare<-make.rarefy2(model1.ps, 100 * sample_data(model1.ps)$DensityF.model1)  # define DensityF.model1 etc
#model2.pRare<-make.rarefy2(model2.ps, 100 * sample_data(model2.ps)$DensityF.model2) # skip??


# scaled ####
model1.scaled<-make.scaled1(model1.ps, val=sample_data(model1.ps)$DensityF.model1, scale = 100)
#model2.scaled<-make.scaled(model2.ps, val=sample_data(model2.ps)$DensityF.model2, scale = 100) # skipp??

# limma vst ####
model1.Limma.raw<-make.limmaVST(model1.ps, "Factor")
model1.Limma.eRare<-make.limmaVST(model1.eRare, "Factor")
model1.Limma.pRare<-make.limmaVST(model1.pRare, "Factor")
model1.Limma.scaled<-make.limmaVST(model1.scaled, "Factor")

#model2.Limma.raw<-make.limmaVST(model2.ps, "Factor")
#model2.Limma.eRare<-make.limmaVST(model2.eRare, "Factor")
#model2.Limma.pRare<-make.limmaVST(model2.pRare, "Factor")
#model2.Limma.scaled<-make.limmaVST(model2.scaled, "Factor")

# Deseq2 vst ####

model1.deseq.raw<-make.deseqVST(model1.ps, "Factor", l=1)
model1.deseq.eRare<-make.deseqVST(model1.eRare, "Factor", l=1) 
model1.deseq.pRare<-make.deseqVST(model1.pRare, "Factor", l=1) # error not enough dispersion
model1.deseq.scaled<-make.deseqVST(model1.scaled, "Factor") # error not enough dispersion

#model2.deseq.raw<-make.deseqVST(model2.ps, "Factor")
#model2.deseq.eRare<-make.deseqVST(model2.eRare, "Factor")
#model2.deseq.pRare<-make.deseqVST(model2.pRare, "Factor")
#model2.deseq.scaled<-make.deseqVST(model2.scaled, "Factor")

```
Build a script to run the following platforms:

DESeq2
Limma Trend <- uses EdgeR 
EdgeR <- already there
BBSeq  <- nope! bisulfide sequencing...
DSS <- um...
BaySeq <- meh
ShrinkBayes <- meh
PoissonSeq <- this one!!

Now we build out the test key
```{r}
# zero is no change, 1 is increase, -1 is decrease
model.key<-data.frame("one"=c(rep(0,15)),"two"=c(rep(1,15)), "three" = c(0,0,0,0,1,-1,0,0,0,0,0,0,1,-1,0), "four" =c(rep(1, 15)), "five"= c(0,0,0,0,1,0,0,0,0,0,0,1,0,0,0), "six"=c(rep(1, 15)), "seven"=c(0,0,0,0,0,0,-1,0,0,0,0,0,0,0,-1), "eight"=c(rep(1,15)), "nine"=c(0,0,0,-1,0,-1,0,0,0,0,0,0,-1,0,0), "ten"=c(1,1,1,-1,1,-1,1,1,1,1,1,1,-1,1,1), "eleven"=c(0,0,0,0,0,0,0,0,0,0,0,0,1,1,1), "twelve"= c(1,1,1,1,1,1,1,1,1,1,1,1,0,0,0))
rownames(model.key)<-paste("sp", 1:15, sep=".")
model.key
```

Run test of environmental correlation:


```{r}

```
If we want to test for all decreasing effects, we can set number two as zero in the comparison tables.


Run test of indicators:
```{r}

limma.Indics<-function(ps, Factor){
  
  counts<-as.data.frame(as.matrix(otu_table(ps)))
  factors<-sample_data(ps)$Factor
  factors<-factor(factors, levels(factors)[c(6,12,10,4,3,8,7,1,5,9,2,11)])
  design<-model.matrix(~0+factors)
  contr.matrix<- makeContrasts(
  TwoVOne = factorstwo-factorsone, 
  ThreeVOne = factorsthree-factorsone, 
  FourVOne = factorsfour-factorsone, 
  FiveVOne = factorsfive-factorsone,
  SixVOne = factorssix-factorsone,
  SevenVOne = factorsseven-factorsone,
  EightVOne = factorseight-factorsone,
  NineVOne = factorsnine-factorsone,
  TenVOne = factorsten-factorsone, 
  ElevenVOne = factorseleven-factorsone,
  TwelveVOne = factorstwelve-factorsone, 
  levels = colnames(design))
  dge <- DGEList(counts=counts)
  dge <- calcNormFactors(dge) #what happens if we don't do this step?
  v<-voom(dge, design, plot=F)
  fitV <- lmFit(v, design)
  fitV <- contrasts.fit(fitV, contrasts=contr.matrix)
  fitV <- eBayes(fitV, trend=TRUE)
  sig<-decideTests(fitV)
  sig
}

library(data.table)
model1.Raw.Limmaindics<-as.data.frame(limma.Indics(model1.ps, "Factor"))
model1.eRare.Limmaindics<-as.data.frame(limma.Indics(model1.eRare, "Factor"))
model1.pRare.Limmaindics<-as.data.frame(limma.Indics(model1.pRare, "Factor"))
model1.scaled.Limmaindics<-as.data.frame(limma.Indics(model1.scaled, "Factor"))

summary(aov(as.data.frame(as.matrix(t(otu_table(model1.eRare))))$sp.14~sample_data(model1.eRare)$Factor))
t<-TukeyHSD(aov(as.data.frame(as.matrix(t(otu_table(model1.eRare))))$sp.14~sample_data(model1.eRare)$Factor))
t2<-as.data.frame(t$`sample_data(model1.eRare)$Factor`[rownames(t$`sample_data(model1.eRare)$Factor`) %like% "one",])

summary(aov(as.data.frame(as.matrix(t(otu_table(model1.pRare))))$sp.14~sample_data(model1.pRare)$Factor))
t<-TukeyHSD(aov(as.data.frame(as.matrix(t(otu_table(model1.pRare))))$sp.14~sample_data(model1.pRare)$Factor))
prare.t2<-as.data.frame(t$`sample_data(model1.pRare)$Factor`[rownames(t$`sample_data(model1.pRare)$Factor`) %like% "one",])

summary(aov(as.data.frame(as.matrix(t(otu_table(model1.scaled))))$sp.14~sample_data(model1.scaled)$Factor))
t<-TukeyHSD(aov(as.data.frame(as.matrix(t(otu_table(model1.scaled))))$sp.14~sample_data(model1.scaled)$Factor))
scaled.t2<-as.data.frame(t$`sample_data(model1.scaled)$Factor`[rownames(t$`sample_data(model1.scaled)$Factor`) %like% "one",])

summary(aov(as.data.frame(as.matrix(t(otu_table(model1.ps))))$sp.14~sample_data(model1.ps)$Factor))
t<-TukeyHSD(aov(as.data.frame(as.matrix(t(otu_table(model1.ps))))$sp.14~sample_data(model1.ps)$Factor))
raw.t2<-as.data.frame(t$`sample_data(model1.ps)$Factor`[rownames(t$`sample_data(model1.ps)$Factor`) %like% "one",])

summary(aov(as.data.frame(as.matrix(t(otu_table(model1.Limma.raw))))$sp.14~sample_data(model1.Limma.raw)$Factor))
t<-TukeyHSD(aov(as.data.frame(as.matrix(t(otu_table(model1.Limma.raw))))$sp.14~sample_data(model1.Limma.raw)$Factor))
limmaVST.t2<-as.data.frame(t$`sample_data(model1.Limma.raw)$Factor`[rownames(t$`sample_data(model1.Limma.raw)$Factor`) %like% "one",])

summary(aov(as.data.frame(as.matrix(t(otu_table(model1.deseq.raw))))$sp.14~sample_data(model1.deseq.raw)$Factor))
t<-TukeyHSD(aov(as.data.frame(as.matrix(t(otu_table(model1.deseq.raw))))$sp.14~sample_data(model1.deseq.raw)$Factor))
t2<-as.data.frame(t$`sample_data(model1.deseq.raw)$Factor`[rownames(t$`sample_data(model1.deseq.raw)$Factor`) %like% "one",])


heatdf<-data.frame("AOV.scaled"=scaled.t2$`p adj`, "AOV.Prare"=prare.t2$`p adj`, "AOV.raw"=raw.t2$`p adj`, "AOV.limmaVST"=limmaVST.t2$`p adj`)
k1<-c(1,1,0,1,0,0,1,1,1,0,1)
k1<-c(T,T,F,T,F,F,T,T,T,F,T)
k.df<-c(k1, k1, k1, k1)
heatdf<-heatdf<=0.05

heat.df<-heatdf==k.df
heat.df$ID<-rownames(t2)

heat<-melt(heat.df, id.var=ID)
ggplot(heat, aes())


rownames(heat.df)<-rownames(t2)
heat.df<-lapply(heat.df, numeric)
heatmap(numeric(as.character(heat.df)))
```

```{R}

model2.Raw.Limmaindics<-as.data.frame(limma.Indics2(model2.ps, "Factor"))
model2.eRare.Limmaindics<-as.data.frame(limma.Indics(model2.eRare, "Factor"))
model2.pRare.Limmaindics<-as.data.frame(limma.Indics(model2.pRare, "Factor"))
model2.scaled.Limmaindics<-as.data.frame(limma.Indics(model2.scaled, "Factor"))

summary(aov(as.data.frame(as.matrix(t(otu_table(model1.eRare))))$sp.14~sample_data(model1.eRare)$Factor))
t<-TukeyHSD(aov(as.data.frame(as.matrix(t(otu_table(model1.eRare))))$sp.14~sample_data(model1.eRare)$Factor))
t2<-as.data.frame(t$`sample_data(model1.eRare)$Factor`[rownames(t$`sample_data(model1.eRare)$Factor`) %like% "one",])

summary(aov(as.data.frame(as.matrix(t(otu_table(model1.pRare))))$sp.14~sample_data(model1.pRare)$Factor))
t<-TukeyHSD(aov(as.data.frame(as.matrix(t(otu_table(model1.pRare))))$sp.14~sample_data(model1.pRare)$Factor))
prare.t2<-as.data.frame(t$`sample_data(model1.pRare)$Factor`[rownames(t$`sample_data(model1.pRare)$Factor`) %like% "one",])

summary(aov(as.data.frame(as.matrix(t(otu_table(model1.scaled))))$sp.14~sample_data(model1.scaled)$Factor))
t<-TukeyHSD(aov(as.data.frame(as.matrix(t(otu_table(model1.scaled))))$sp.14~sample_data(model1.scaled)$Factor))
scaled.t2<-as.data.frame(t$`sample_data(model1.scaled)$Factor`[rownames(t$`sample_data(model1.scaled)$Factor`) %like% "one",])

summary(aov(as.data.frame(as.matrix(t(otu_table(model1.ps))))$sp.14~sample_data(model1.ps)$Factor))
t<-TukeyHSD(aov(as.data.frame(as.matrix(t(otu_table(model1.ps))))$sp.14~sample_data(model1.ps)$Factor))
raw.t2<-as.data.frame(t$`sample_data(model1.ps)$Factor`[rownames(t$`sample_data(model1.ps)$Factor`) %like% "one",])

summary(aov(as.data.frame(as.matrix(t(otu_table(model1.Limma.raw))))$sp.14~sample_data(model1.Limma.raw)$Factor))
t<-TukeyHSD(aov(as.data.frame(as.matrix(t(otu_table(model1.Limma.raw))))$sp.14~sample_data(model1.Limma.raw)$Factor))
limmaVST.t2<-as.data.frame(t$`sample_data(model1.Limma.raw)$Factor`[rownames(t$`sample_data(model1.Limma.raw)$Factor`) %like% "one",])

summary(aov(as.data.frame(as.matrix(t(otu_table(model1.deseq.raw))))$sp.14~sample_data(model1.deseq.raw)$Factor))
t<-TukeyHSD(aov(as.data.frame(as.matrix(t(otu_table(model1.deseq.raw))))$sp.14~sample_data(model1.deseq.raw)$Factor))
t2<-as.data.frame(t$`sample_data(model1.deseq.raw)$Factor`[rownames(t$`sample_data(model1.deseq.raw)$Factor`) %like% "one",])
```

# environmental workflow!!

the samples so far follow the same basic distribution, with minor tweaks to the order of the taxa within the distribution. What happens if we make a distribution that has substantial patchiness among samples? This requires a very different modeling approach. 

The purpose of this next modeling framework is to illustrate how normalization affects inference of both environmental gradient detection, and interacts with more realistic uncertainty.

We are going to examine the role of sparcity. [] illustrate that the microbial community can be viewed as being partitioned between species that are in effect randomly distributed and those that are central and abundant to a specific set of samples. The key is to distinguish these distributional patterns and extract the important environmental relationships from them. It is imporant to note that some relationships that may appear random are in fact driven by real filtering effects that are simply not being measured.

```{r pressure, echo=FALSE}
AllSpp<-c(paste0("spp", c(1:700), sep="")) # make a quick list of all species functions
AllSpp<-lapply(AllSpp, get) # connect function to name
AllSpp<-unlist(AllSpp)  # format to be read by downstream functions

names(AllSpp)<-c(paste0("spp", c(1:700)))


# if desired: seeds<-round(rnorm(50,5000,100)) 
# set.seed(seeds[1]) # 4945
Comm1<-base::sample(AllSpp, 50, replace=F) # pick 200 random taxa from pool
#set.seed(seeds[2]) # 4902
#Comm2<-base::sample(AllSpp, 50, replace=F) # pick 200 random taxa from pool
#set.seed(seeds[4]) # 5098
#Comm3<-base::sample(AllSpp, 50, replace=F) # pick 200 random taxa from pool

names(Comm1)
#names(Comm2)
#names(Comm3)




library(reshape2)
f1c1<-c(5,5,5,5,5,5) # number of selections
f1c2<-c(1,3,10,30,60,15) # mean value of selections
f1c3<-c(0.5,1,4,10,20,5) # SD of selections
F1.frame<-mapply(rnorm, f1c1,f1c2,f1c3) # pick Factor 1 value for each site
F1<-reshape2::melt(F1.frame)

#F2
f2c1<-c(5,5,5,5,5,5) # number of selections
f2c2<-c(34,30,10,55,35,60) # mean value of selections
f2c3<-c(10,10,3,10,1,20) # SD of selections
F2.frame<-mapply(rnorm, f2c1,f2c2,f2c3) # pick Factor 2 value for each site
F2<-reshape2::melt(F2.frame)

#F3
f3c1<-c(5,5,5,5,5,5) # number of selections
f3c2<-c(1,3,10,15,3,15) # mean value of selections
f3c3<-c(0.5,1,3,3,1,5) # SD of selections
F3.frame<-mapply(rnorm, f3c1,f3c2,f3c3) # pick Factor 3 value for each site
F3<-reshape2::melt(F3.frame)

#F4
f4c1<-c(5,5,5,5,5,5) # number of selections
f4c2<-c(1,3,10,15,3,15) # mean value of selections
f4c3<-c(0.5,0.5,3,3,1,5) # SD of selections
F4.frame<-mapply(rnorm, f4c1,f4c2,f4c3) # pick Factor 4 value for each site
F4<-reshape2::melt(F4.frame)

#F5
f5c1<-c(5,5,5,5,5,5) # number of selections
f5c2<-c(50,40,30,20,10,15) # mean value of selections
f5c3<-c(20,10,10,5,3,5) # SD of selections
F5.frame<-mapply(rnorm, f5c1,f5c2,f5c3) # pick Factor 5 value for each site
F5<-reshape2::melt(F5.frame)

Factors<-data.frame(F1$value,F2$value,F3$value,F4$value,F5$value) # combine factors into data table
Sites<-c(paste0("Site", 1:30))
rownames(Factors)<-Sites
colnames(Factors)<-c("F1","F2","F3","F4","F5")
head(Factors)

saveRDS(Factors, "~/Documents/Github/ModelMicrobiome/Model_environment.RDS") # save environmental gradient!!

#### output response table ###

# modeled environment ... 

f1c1.2<-c(1000,1000,1000,1000,1000,1000) # number of selections
F1.frame2<-mapply(rnorm, f1c1.2,f1c2,f1c3) # pick Factor 1 value for each site
F1.2<-reshape2::melt(F1.frame2)

#F2
f2c1.2<-c(1000,1000,1000,1000,1000,1000) # number of selections
F2.frame2<-mapply(rnorm, f2c1.2,f2c2,f2c3) # pick Factor 2 value for each site
F2.2<-reshape2::melt(F2.frame2)

#F3
f3c1.2<-c(1000,1000,1000,1000,1000,1000) # number of selections
F3.frame2<-mapply(rnorm, f3c1.2,f3c2,f3c3) # pick Factor 3 value for each site
F3.2<-reshape2::melt(F3.frame2)

#F4
f4c1.2<-c(1000,1000,1000,1000,1000,1000) # number of selections
F4.frame2<-mapply(rnorm, f4c1.2,f4c2,f4c3) # pick Factor 4 value for each site
F4.2<-reshape2::melt(F4.frame2)

#F5
f5c1.2<-c(1000,1000,1000,1000,1000,1000) # number of selections
F5.frame2<-mapply(rnorm, f5c1.2,f5c2,f5c3) # pick Factor 5 value for each site
F5.2<-reshape2::melt(F5.frame2)

Factors.2<-data.frame(F1.2$value,F2.2$value,F3.2$value,F4.2$value,F5.2$value) # combine factors into data table
Sites.2<-c(paste0("Site", 1:6000))
rownames(Factors.2)<-Sites.2
colnames(Factors.2)<-c("F1","F2","F3","F4","F5")

# builds an OTU table from species equations and factors
make.comm<-function(Comm1, Factors){
otu<-matrix(data=NA, nrow=nrow(Factors), ncol = length(Comm1))
Sites<-c(paste0("Site", 1:30))
for(i in 1:length(Comm1)) {
  for(row in 1:nrow(Factors)){
   otu[row,i]<-do.call(Comm1[[i]], list(Factors[row,1],Factors[row,2],Factors[row,3],Factors[row,4],Factors[row,5]))
      }
}

row.names(otu)<-Sites
colnames(otu)<-names(Comm1)
otu[mapply(is.infinite, otu)] <- NA
otu[is.nan(otu)]<-NA
otu[is.na(otu)]<-0
otu[otu<0]<-0
otu<-round(otu)
otu<-otu_table(otu, taxa_are_rows = FALSE)
Sa<-sample_data(Factors)
out<-phyloseq(otu, Sa)
out}

model2<-make.comm(Comm1, Factors)
sample_data(model2)$total_abund<-sample_sums(model2)
model2 # needs to be subsampled yet in order to represent sequencing process
sample_sums(model2)

#saveRDS(out, "~/Documents/GitHub/ModelMicrobiome/PS_envComm.RDS")
```

Now let's preprossess the sample data
```{R}
sample2<-rnorm(30, 2000, 1000)
sample2<-round(abs(sample2)) # Sequencing depth to sample
model2.raw<-make.rarefy1(model2, sample2)
otu_table(model2.raw)
sample_sums(model2.raw)

sample_data(model2.raw)$Factor<-as.factor(c(rep("one",5),rep("two",5),rep("three",5),rep("four",5),rep("five",5),rep("six",5)))
sample_data(model2.raw)$Factor2<-as.factor(c(rep(1,5),rep(2,5),rep(3,5),rep(4,5),rep(5,5),rep(6,5)))

```
Let's explore the role that sequencing variation has on inference!

Remember that model4 is defined...
```{R}
# VSI ####

# function for setting sequencing/sampling depth per sample
# b = mean value
# c = varition
set.seqDepth<-function(b, c){
  d1<-rnorm(30, b, c)
  d1[d1<0]<-0
  d2<-rnorm(30, 100, 10)# because typically there is at least some low level number of counts
  depth=d1+d2
  depth<-round(depth)
  depth
}

# function for testing the relationship between sequencing depth/var and predictive power
# do 10 reps across 3 levels and 5 variances is 150 points
benchmark.norm<-function(model){
  val<-data.frame("mean level"=c(rep(20, 50), rep(200, 50), rep(2000, 50)), "var level"=c(rep(c(rep(1, 10), rep(10, 10), rep(100, 10), rep(1000, 10), rep(10000, 10)), 3)), "Index"=c(rep(0, 150)))
  Index=NULL
  
  for(i in 1:nrow(val)){
    seq.depth<-set.seqDepth(val[i,1], val[i,2])
    otu<-make.rarefy2(model, seq.depth)
    
    Ri<-as.matrix(as.data.frame(t(as.matrix(otu_table(Delta.sppcount(model, model, method=0))))))
    Ai<-as.matrix(as.data.frame(t(as.matrix(otu_table(Delta.sppcount(otu, model, method=0))))))
    Ci<-sum(sapply(seq.int(dim(R)[2]), function(i) sum(abs(Ri[,i] - Ai[,i]))))
    
    #val[i,3]<-Ci
    Index[i]<-Ci
  }
  
#val$Index<-Index
val$Index<-Index
val
}

BM.model4<-benchmark.norm(model=model4)
BM.model4
# pipeline tests
set.seqDepth(2000,10000)


BM.model4$mv.Ratio<-BM.model4$var.level/BM.model4$mean.level


with(BM.model4, plot(Index~jitter(mean.level), col=var.level))

with(BM.model4, plot(Index~jitter(log(mv.Ratio)), col=var.level))

ggplot(BM.model4, aes(y=Index, x=log(mv.Ratio), color=as.factor(mean.level)))+theme_classic()+geom_point()
ggplot(BM.model4, aes(y=Index, x=log(mv.Ratio), color=as.factor(var.level)))+theme_classic()+geom_point()

View(BM.model4)
```

```{r}



```

```{r}
sample2<-round(abs(sample2)) # Sequencing depth to sample
model2.raw<-make.rarefy1(model2, sample2)
otu_table(model2.raw)
sample_sums(model2.raw)

sample_data(model2.raw)$Factor<-as.factor(c(rep("one",5),rep("two",5),rep("three",5),rep("four",5),rep("five",5),rep("six",5)))
sample_data(model2.raw)$Factor2<-as.factor(c(rep(1,5),rep(2,5),rep(3,5),rep(4,5),rep(5,5),rep(6,5)))

```

Most rarefaction protocols select a single value to subsample the entire community to. This looks something like this:
```{R}

model2.eRare<-make.rarefy2(model2.raw, min(sample_sums(model2.raw))-1)
```

An alternative is to use an external measure of community density, such as QPCR to scale the depth of sampling. In this case we use the sequencing-independent relative density of each sample to correct the overal sampling depth. A key challenge here is that this means that even the most well-sequenced samples may end up getting thrown out because they are still undersampled compared to other samples. But, if community densities are within a few orders of magnitude, and each sample has close to a hundred thousand sequences, then most samples should be preserved.

```{R}
norm.model2<-round((sample_data(model2.raw)$total_abund/mean(sample_data(model2.raw)$total_abund))*400)
model2.pRare<-make.rarefy2(model2.raw, norm.model2)
```

An alternative is to use the sequencing as a distribution and scale the total abundance to the independent measure of community density. 
```{R}
model2.scaled<-make.scaled2(model2.raw, val=norm.model2/400, scale = 1000)
model2.scaled
```

```{R}
model2.limmaVST<-make.limmaVST(model2.raw, "Factor")
model2.limmaVST
```

```{R}
model2.DeseqVST<-make.limmaVST(model2.raw, "Factor")
model2.DeseqVST
```
the samples so far follow the same basic distribution, with minor tweaks to the order of the taxa within the distribution. What happens if we make a distribution that has substantial patchiness among samples? This requires a very different modeling approach. Here we construct a community where the samples are primarily occupied by uniique taxa. In this instance there are 10 taxa that are randomly chosen to be globally distributed. For each sampling category, there are 20 taxa that are randomly chosen to be regionally distributed. And then for each sample, there are 70 taxa that are chosen to be abundant in that sample. These taxa are chosen from a pool of YYYY taxa and are chosen with replacement between selection rounds, but without replacement within each selection round. Therefore a taxon may be chosen in the global taxon selection, the regional taxon selection and the sample-wise taxon selection. Therefore total alpha diversity among samples varies somewhat and sometimes does not equal 100. Again, between samples there may be some minor overlap between selections for sample-wise taxa; and between regions there may be some overlap between region-wise taxa. This is desireable as a representation of actual multi-scalar diversity in distribution of individual taxa. Since we have the species lists, we have a key to correct any incorrect inference about the distribution of taxa. 

It is also important to realize that the taxon abundances are modeled based on the environmental parameters. Therefore, although we have selected a taxon to exist in a site, the taxon itself may not survive in those conditions. Thus we are inflating the number of absences compared to our previous sampling approach. However, the advantage of this method over the previous one is that now we have taxa whose abundance is not solely modeled on known paramters.

```{r}
# the samples so far follow the same basic distribution, with minor tweaks to the order of the taxa within the distribution. What happens if we make a distribution that has substantial patchiness among samples?

AllSpp<-c(paste0("spp", c(1:700), sep="")) # trying to make a quick list of all functions
AllSpp<-lapply(AllSpp, get)
AllSpp<-unlist(AllSpp)

names(AllSpp)<-c(paste0("spp", c(1:700)))

library(plyr)
# Define list of 5 species w/ global distribution
global.spp<-names(sample(AllSpp, 5, replace=F))

# define list of species w/ regional distribution
group.spp<-NULL
group.spp$group1<-names(sample(AllSpp, 20, replace=F))
group.spp$group2<-names(sample(AllSpp, 20, replace=F))
group.spp$group3<-names(sample(AllSpp, 20, replace=F))
group.spp$group4<-names(sample(AllSpp, 20, replace=F))
group.spp$group5<-names(sample(AllSpp, 20, replace=F))
group.spp$group6<-names(sample(AllSpp, 20, replace=F))

# define list of species found at each site
rando.spp<-NULL
rando.spp$Site1<-unique(c(names(sample(AllSpp, 50, replace=F)), c(group.spp$group1), global.spp))
rando.spp$Site2<-unique(c(names(sample(AllSpp, 50, replace=F)), c(group.spp$group1), global.spp))
rando.spp$Site3<-unique(c(names(sample(AllSpp, 50, replace=F)), c(group.spp$group1), global.spp))
rando.spp$Site4<-unique(c(names(sample(AllSpp, 50, replace=F)), c(group.spp$group1), global.spp))
rando.spp$Site5<-unique(c(names(sample(AllSpp, 50, replace=F)), c(group.spp$group1), global.spp))
rando.spp$Site6<-unique(c(names(sample(AllSpp, 50, replace=F)), c(group.spp$group2), global.spp))
rando.spp$Site7<-unique(c(names(sample(AllSpp, 50, replace=F)), c(group.spp$group2), global.spp))
rando.spp$Site8<-unique(c(names(sample(AllSpp, 50, replace=F)), c(group.spp$group2), global.spp))
rando.spp$Site9<-unique(c(names(sample(AllSpp, 50, replace=F)), c(group.spp$group2), global.spp))
rando.spp$Site10<-unique(c(names(sample(AllSpp,50, replace=F)), c(group.spp$group2), global.spp))
rando.spp$Site11<-unique(c(names(sample(AllSpp, 50, replace=F)), c(group.spp$group3), global.spp))
rando.spp$Site12<-unique(c(names(sample(AllSpp, 50, replace=F)), c(group.spp$group3), global.spp))
rando.spp$Site13<-unique(c(names(sample(AllSpp, 50, replace=F)), c(group.spp$group3), global.spp))
rando.spp$Site14<-unique(c(names(sample(AllSpp, 50, replace=F)), c(group.spp$group3), global.spp))
rando.spp$Site15<-unique(c(names(sample(AllSpp, 50, replace=F)), c(group.spp$group3), global.spp))
rando.spp$Site16<-unique(c(names(sample(AllSpp, 50, replace=F)), c(group.spp$group4), global.spp))
rando.spp$Site17<-unique(c(names(sample(AllSpp, 50, replace=F)), c(group.spp$group4), global.spp))
rando.spp$Site18<-unique(c(names(sample(AllSpp, 50, replace=F)), c(group.spp$group4), global.spp))
rando.spp$Site19<-unique(c(names(sample(AllSpp, 50, replace=F)), c(group.spp$group4), global.spp))
rando.spp$Site20<-unique(c(names(sample(AllSpp, 50, replace=F)), c(group.spp$group4), global.spp))
rando.spp$Site21<-unique(c(names(sample(AllSpp, 50, replace=F)), c(group.spp$group5), global.spp))
rando.spp$Site22<-unique(c(names(sample(AllSpp, 50, replace=F)), c(group.spp$group5), global.spp))
rando.spp$Site23<-unique(c(names(sample(AllSpp, 50, replace=F)), c(group.spp$group5), global.spp))
rando.spp$Site24<-unique(c(names(sample(AllSpp, 50, replace=F)), c(group.spp$group5), global.spp))
rando.spp$Site25<-unique(c(names(sample(AllSpp, 50, replace=F)), c(group.spp$group5), global.spp))
rando.spp$Site26<-unique(c(names(sample(AllSpp, 50, replace=F)), c(group.spp$group6), global.spp))
rando.spp$Site27<-unique(c(names(sample(AllSpp, 50, replace=F)), c(group.spp$group6), global.spp))
rando.spp$Site28<-unique(c(names(sample(AllSpp, 50, replace=F)), c(group.spp$group6), global.spp))
rando.spp$Site29<-unique(c(names(sample(AllSpp, 50, replace=F)), c(group.spp$group6), global.spp))
rando.spp$Site30<-unique(c(names(sample(AllSpp, 50, replace=F)), c(group.spp$group6), global.spp))

rando.spp # examine lists


# function for making the environmental community !!
make.comm2<-function(rando.spp, Factors){
l1<-NULL
for (i in 1:length(rando.spp[[1]])){
  l1[i]<-do.call(rando.spp[[1]][i], list(Factors[1,1],Factors[1,2],Factors[1,3],Factors[1,4],Factors[1,5]))
  }
#l1<-data.frame("Site1"=l1, "Spp"=rando.spp[[1]])
names(l1)<-rando.spp[[1]]
for (r in 2:nrow(Factors)) # for each site...
{ l2<-NULL
  for (i in 1:length(rando.spp[[r]])){  # for each species in site...
    l2[i]<-do.call(rando.spp[[r]][i], list(Factors[r,1],Factors[r,2],Factors[r,3],Factors[r,4],Factors[r,5]))
    }
  names(l2)<-rando.spp[[r]]
  l1<-merge(as.data.frame(l1),as.data.frame(l2), by=0, all=T)
  rownames(l1)<-l1$Row.names
  colnames(l1)[colnames(l1) == "l1"] <- "Site1"
 colnames(l1)[colnames(l1) == "l2"] <- paste("Site", r, sep="")
 l1<-l1[,-1]
  }
l1<-round(l1)
l1[mapply(is.infinite, l1)] <- NA
l1[is.na(l1)]<-0
l1[l1<0]<-0
otu<-otu_table(l1, taxa_are_rows = T)
Sa<-sample_data(Factors)
out<-phyloseq(otu, Sa)
out
}

```

```{r}

# test species-abundance curve ####
AllSpp<-c(paste0("spp", c(1:700), sep="")) # trying to make a quick list of all functions
AllSpp<-lapply(AllSpp, get)
AllSpp<-unlist(AllSpp)

names(AllSpp)<-c(paste0("spp", c(1:700)))

global.spp<-names(AllSpp)

rank.abundance<-make.comm(global.spp, Factors)

par(mfrow=c(2,2))
barplot(sort(taxa_sums(rank.abundance), TRUE), 
    las = 2)
barplot(sort(taxa_sums(rank.abundance), TRUE)[300:700], 
    las = 2)
barplot(sort(taxa_sums(rank.abundance), TRUE)[400:700], 
    las = 2)
barplot(sort(taxa_sums(rank.abundance), TRUE)[500:700], 
    las = 2)

names(taxa_sums(rank.abundance))[578:700]
```

```{r}
# Define list of 50 species w/ global distribution
global2.spp<-names(sample(AllSpp, 50, replace=F))

# define list of species w/ regional distribution
group2.spp<-NULL
group2.spp$group1<-names(sample(AllSpp, 20, replace=F))
group2.spp$group2<-names(sample(AllSpp, 20, replace=F))
group2.spp$group3<-names(sample(AllSpp, 20, replace=F))
group2.spp$group4<-names(sample(AllSpp, 20, replace=F))
group2.spp$group5<-names(sample(AllSpp, 20, replace=F))
group2.spp$group6<-names(sample(AllSpp, 20, replace=F))

# define list of species found at each site
rando2.spp<-NULL
rando2.spp$Site1<-unique(c(names(sample(AllSpp, 10, replace=F)), c(group2.spp$group1), global2.spp))
rando2.spp$Site2<-unique(c(names(sample(AllSpp, 10, replace=F)), c(group2.spp$group1), global2.spp))
rando2.spp$Site3<-unique(c(names(sample(AllSpp, 10, replace=F)), c(group2.spp$group1), global2.spp))
rando2.spp$Site4<-unique(c(names(sample(AllSpp, 10, replace=F)), c(group2.spp$group1), global2.spp))
rando2.spp$Site5<-unique(c(names(sample(AllSpp, 10, replace=F)), c(group2.spp$group1), global2.spp))
rando2.spp$Site6<-unique(c(names(sample(AllSpp, 10, replace=F)), c(group2.spp$group2), global2.spp))
rando2.spp$Site7<-unique(c(names(sample(AllSpp, 10, replace=F)), c(group2.spp$group2), global2.spp))
rando2.spp$Site8<-unique(c(names(sample(AllSpp, 10, replace=F)), c(group2.spp$group2), global2.spp))
rando2.spp$Site9<-unique(c(names(sample(AllSpp, 10, replace=F)), c(group2.spp$group2), global2.spp))
rando2.spp$Site10<-unique(c(names(sample(AllSpp,10, replace=F)), c(group2.spp$group2), global2.spp))
rando2.spp$Site11<-unique(c(names(sample(AllSpp, 10, replace=F)), c(group2.spp$group3), global2.spp))
rando2.spp$Site12<-unique(c(names(sample(AllSpp, 10, replace=F)), c(group2.spp$group3), global2.spp))
rando2.spp$Site13<-unique(c(names(sample(AllSpp, 10, replace=F)), c(group2.spp$group3), global2.spp))
rando2.spp$Site14<-unique(c(names(sample(AllSpp, 10, replace=F)), c(group2.spp$group3), global2.spp))
rando2.spp$Site15<-unique(c(names(sample(AllSpp, 10, replace=F)), c(group2.spp$group3), global2.spp))
rando2.spp$Site16<-unique(c(names(sample(AllSpp, 10, replace=F)), c(group2.spp$group4), global2.spp))
rando2.spp$Site17<-unique(c(names(sample(AllSpp, 10, replace=F)), c(group2.spp$group4), global2.spp))
rando2.spp$Site18<-unique(c(names(sample(AllSpp, 10, replace=F)), c(group2.spp$group4), global2.spp))
rando2.spp$Site19<-unique(c(names(sample(AllSpp, 10, replace=F)), c(group2.spp$group4), global2.spp))
rando2.spp$Site20<-unique(c(names(sample(AllSpp, 10, replace=F)), c(group2.spp$group4), global2.spp))
rando2.spp$Site21<-unique(c(names(sample(AllSpp, 10, replace=F)), c(group2.spp$group5), global2.spp))
rando2.spp$Site22<-unique(c(names(sample(AllSpp, 10, replace=F)), c(group2.spp$group5), global2.spp))
rando2.spp$Site23<-unique(c(names(sample(AllSpp, 10, replace=F)), c(group2.spp$group5), global2.spp))
rando2.spp$Site24<-unique(c(names(sample(AllSpp, 10, replace=F)), c(group2.spp$group5), global2.spp))
rando2.spp$Site25<-unique(c(names(sample(AllSpp, 10, replace=F)), c(group2.spp$group5), global2.spp))
rando2.spp$Site26<-unique(c(names(sample(AllSpp, 10, replace=F)), c(group2.spp$group6), global2.spp))
rando2.spp$Site27<-unique(c(names(sample(AllSpp, 10, replace=F)), c(group2.spp$group6), global2.spp))
rando2.spp$Site28<-unique(c(names(sample(AllSpp, 10, replace=F)), c(group2.spp$group6), global2.spp))
rando2.spp$Site29<-unique(c(names(sample(AllSpp, 10, replace=F)), c(group2.spp$group6), global2.spp))
rando2.spp$Site30<-unique(c(names(sample(AllSpp, 10, replace=F)), c(group2.spp$group6), global2.spp))

rando2.spp # examine lists
```

Do the different pre-prosessing and differential expression analyses...

```{R}
make.refcomm<-function(rando.spp, Factors){
l1<-NULL
for (i in 1:length(rando.spp[[1]])){
  l1[i]<-do.call(rando.spp[[1]][i], list(Factors[1,1],Factors[1,2],Factors[1,3],Factors[1,4],Factors[1,5]))
  }
#l1<-data.frame("Site1"=l1, "Spp"=rando.spp[[1]])
names(l1)<-rando.spp[[1]]
for (r in 2:nrow(Factors)) # for each site...
{ l2<-NULL
  for (i in 1:length(rando.spp[[r]])){  # for each species in site...
    l2[i]<-do.call(rando.spp[[r]][i], list(Factors[r,1],Factors[r,2],Factors[r,3],Factors[r,4],Factors[r,5]))
    }
  names(l2)<-rando.spp[[r]]
  l1<-merge(as.data.frame(l1),as.data.frame(l2), by=0, all=T)
  rownames(l1)<-l1$Row.names
  colnames(l1)[colnames(l1) == "l1"] <- "Site1"
 colnames(l1)[colnames(l1) == "l2"] <- paste("Site", r, sep="")
 l1<-l1[,-1]
  }
l1<-round(l1)
l1[mapply(is.infinite, l1)] <- NA
l1[is.na(l1)]<-0
l1[l1<0]<-0
otu<-otu_table(l1, taxa_are_rows = T)
Sa<-sample_data(Factors)
out<-phyloseq(otu, Sa)
out
}

site.list<-paste("site", 1:6000, sep = "")
spp.list<-names(AllSpp)
sppKey<-lapply(site.list, function(x) x<-spp.list)
names(sppKey)<-paste("site", 1:6000, sep = "")


null.model<-make.refcomm(sppKey, Factors.2) #can take some time...
sample_data(null.model)$Factor<-c(rep("one", 1000), rep("two", 1000), rep("three", 1000), rep("four", 1000), rep("five", 1000), rep("six", 1000))

```


```{R}
# make the sample key table for taxa

Key.Tab.ab<-merge_samples(null.model, "Factor", fun=mean)
Key.Tab.ab<-as.data.frame(as.matrix(otu_table(Key.Tab.ab)))

Key.Tab.sd<-merge_samples(null.model, "Factor", fun=sd)
Key.Tab.sd<-as.data.frame(as.matrix(otu_table(Key.Tab.sd)))

select.key<-function(ps, s.key){
  require(phyloseq)
  
  sp<-taxa_names(ps)
  k<-s.key[c(sp),] # this doesn't work because some species randomly might not exist...
  
}

```


```{R}
model3<-make.comm2(rando.spp, Factors)
model3<-filter_taxa(model3, function(x) sum(x)>0, TRUE) # remove samples that are filtered out by the environmnet

model4<-make.comm2(rando2.spp, Factors)
model4<-filter_taxa(model4, function(x) sum(x)>0, TRUE)

# validate
#sample_sums(model4)
#otu_table(model4)[otu_table(model4)[,29]==max(otu_table(model4)[,29]),29]
# do some testing
#test.mtrx<-t(as.data.frame(as.matrix(otu_table(model4))))

test.nainf<-otu_table(model3.raw)
table(apply(test.nainf, 2, function(x) any(is.na(x)| is.infinite(x)))) # should all be false!!

test.nainf<-otu_table(model4.raw)
table(apply(test.nainf, 2, function(x) any(is.na(x)| is.infinite(x)))) # should all be false!!
# now move on

sample<-rnorm(30, 2000, 1000) # model sequencing depth
sample<-round(abs(sample)) # model sequencing depth

# explanation: We will use the same sequencing depth for both communities in order to directly compare the effect of sparcity on the results

sample_sums(model3) # check sample sums
sample_sums(model4) # check sample sums

model3.raw<-make.rarefy2(model3, sample)
model4.raw<-make.rarefy2(model4, sample)

sample_data(model3.raw)$Factor<-as.factor(c(rep("one",5),rep("two",5),rep("three",5),rep("four",5),rep("five",5),rep("six",5)))
sample_data(model3.raw)$Factor2<-as.factor(c(rep(1,5),rep(2,5),rep(3,5),rep(4,5),rep(5,5),rep(6,5)))

sample_data(model3.raw)$Density<-sample_sums(model3)
sample_data(model3.raw)$DensityF.model3<-sample_data(model3.raw)$Density/mean(sample_data(model3.raw)$Density)

sample_data(model4.raw)$Factor<-as.factor(c(rep("one",5),rep("two",5),rep("three",5),rep("four",5),rep("five",5),rep("six",5)))
sample_data(model4.raw)$Factor2<-as.factor(c(rep(1,5),rep(2,5),rep(3,5),rep(4,5),rep(5,5),rep(6,5)))

sample_data(model4.raw)$Density<-sample_sums(model4)
sample_data(model4.raw)$DensityF.model4<-sample_data(model4.raw)$Density/mean(sample_data(model4.raw)$Density)

sample_data(model4)$Factor<-as.factor(c(rep("one",5),rep("two",5),rep("three",5),rep("four",5),rep("five",5),rep("six",5)))
```

Common filtering schemes:

Many filtering schemes remove many of the more sparsely represented species. This may result in an under representation of the rare microbiome. Here I demonstrate in principle this effect. Later we will see the effect on real datasets.
```{r}
# phyloseq tutorial: https://joey711.github.io/phyloseq/preprocess.html
# this filtering uses minimum mean abundance, and removes singletons. The tutorial also includes a filtering step for coefficient of variation, but this is inappropriate since it could be highly biasing
G.3f = filter_taxa(model3.raw, function(x) sum(x > 3) > (0.2*length(x)), TRUE)
G.3  = transform_sample_counts(G3.f, function(x) x / sum(x) )
G.3 = filter_taxa(G.3, function(x) mean(x) > 1e-5, TRUE)
G.3

G.4f = filter_taxa(model4.raw, function(x) sum(x > 3) > (0.2*length(x)), TRUE)
G.4  = transform_sample_counts(G4.f, function(x) x / sum(x) )
G.4 = filter_taxa(G.4, function(x) mean(x) > 1e-5, TRUE)
G.4

# DESeq2 SOP: http://bioconductor.org/packages/release/bioc/vignettes/DESeq2/inst/doc/DESeq2.html#pre-filtering
# filter to at least 10 counts per taxon

dd.3<-filter_taxa(model3.raw, function(x) sum(x) > 10, TRUE)
dd.4<-filter_taxa(model4.raw, function(x) sum(x) > 10, TRUE)

# limma-voom SOP:
# machine learning approach to keeping genes, ends up being quite conservative
filter.limma<-function(ps){
  x<-as.data.frame(as.matrix(otu_table(ps)))
  group=sample_data(ps)$Factor2
  keep.exprs <- filterByExpr(x, group=group)
  x <- x[keep.exprs,, keep.lib.sizes=FALSE]
  otu_table(ps)<-otu_table(x, taxa_are_rows = TRUE)
  ps
}

x.3<-filter.limma(model3)
x.4<-filter.limma(model4)

lost.tax<-data.frame("model3"=c(ntaxa(G.3), ntaxa(dd.3), ntaxa(x.3)), "model4"=cntaxa(G.4), ntaxa(dd.4), ntaxa(x.4))
rownames(lost.tax)<-c("Phyloseq", "Deseq", "Limma")

```

```{r}
# run each on the normalized model data

```


```{r}
model3.scaled<-make.scaled1(model3.raw, val=sample_data(model3.raw)$DensityF.model3, scale = 1000)
model3.eRare<-make.rarefy2(model3.raw, 900) # get as much depth as possible without losing samples
model3.pRare<-make.rarefy2(model3.raw, 300 * sample_data(model3.raw)$DensityF.model3)

model4.scaled<-make.scaled1(model4.raw, val=sample_data(model4.raw)$DensityF.model4, scale = 1000)
model4.eRare<-make.rarefy2(model4.raw, 900) # get as much depth as possible without losing samples
model4.pRare<-make.rarefy2(model4.raw, 300 * sample_data(model4.raw)$DensityF.model4)

model3.deseq.raw<-make.deseqVST(model3.raw, "Factor")
model3.deseq.eRare<-make.deseqVST(model3.eRare, "Factor")
model3.deseq.pRare<-make.deseqVST(model3.pRare, "Factor")
model3.deseq.scaled<-make.deseqVST(model3.scaled, "Factor")

model4.deseq.raw<-make.deseqVST(model4.raw, "Factor")
model4.deseq.eRare<-make.deseqVST(model4.eRare, "Factor")
model4.deseq.pRare<-make.deseqVST(model4.pRare, "Factor")
model4.deseq.scaled<-make.deseqVST(model4.scaled, "Factor")

model3.Limma.raw<-make.limmaVST(model3.raw, "Factor")
model3.Limma.eRare<-make.limmaVST(model3.eRare, "Factor")
model3.Limma.pRare<-make.limmaVST(model3.pRare, "Factor")
model3.Limma.scaled<-make.limmaVST(model3.scaled, "Factor")

model4.Limma.raw<-make.limmaVST(model4.raw, "Factor")
model4.Limma.eRare<-make.limmaVST(model4.eRare, "Factor")
model4.Limma.pRare<-make.limmaVST(model4.pRare, "Factor")
model4.Limma.scaled<-make.limmaVST(model4.scaled, "Factor")

```

```{R}
limma.Indics3<-function(ps, Factor){
  ps<-filter_taxa(ps, function(x) sum(x)>0, T)
  counts<-as.data.frame(as.matrix(otu_table(ps)))
  factors<-sample_data(ps)$Factor
  factors<-factor(factors, levels(factors)[c(3,6,5,2,1,4)])
  design<-model.matrix(~0+factors)
  contr.matrix<- makeContrasts(
  TwoVOne = factorstwo-factorsone, 
  ThreeVOne = factorsthree-factorsone, 
  FourVOne = factorsfour-factorsone, 
  FiveVOne = factorsfive-factorsone,
  SixVOne = factorssix-factorsone,
  levels = colnames(design))
  dge <- DGEList(counts=counts)
  dge <- calcNormFactors(dge) #what happens if we don't do this step?
  v<-voom(dge, design, plot=F)
  fitV <- lmFit(v, design)
  fitV <- contrasts.fit(fitV, contrasts=contr.matrix)
  fitV <- eBayes(fitV, trend=TRUE)
  sig<-decideTests(fitV)
  sig
}

model3.Raw.Limmaindics<-as.data.frame(limma.Indics3(model3.raw, "Factor"))
model3.eRare.Limmaindics<-as.data.frame(limma.Indics3(model3.eRare, "Factor"))
model3.pRare.Limmaindics<-as.data.frame(limma.Indics3(model3.pRare, "Factor"))
model3.scaled.Limmaindics<-as.data.frame(limma.Indics3(model3.scaled, "Factor"))

model4.Raw.Limmaindics<-as.data.frame(limma.Indics3(model4.raw, "Factor"))
model4.eRare.Limmaindics<-as.data.frame(limma.Indics3(model4.eRare, "Factor"))
model4.pRare.Limmaindics<-as.data.frame(limma.Indics3(model4.pRare, "Factor"))
model4.scaled.Limmaindics<-as.data.frame(limma.Indics3(model4.scaled, "Factor"))


```
```{r}
# Deseq indics
test.df<-phyloseq_to_deseq2(model3.raw, ~Factor)
test.df$condition <- relevel(test.df$condition, ref = "one")
test.geomeans=apply(counts(test.df),1, gm_mean)
test.dds<-estimateSizeFactors(test.df, geoMeans=test.geomeans)
test.dds<-DESeq(test.dds)
test.res<-results(test.dds)

deseq.res<-function(x){
  sample_data(x)$Factor <- relevel(sample_data(x)$Factor, "one")
  r<-phyloseq_to_deseq2(x, ~Factor)
  geoMeans = apply(counts(r), 1, gm_mean)
  dds = estimateSizeFactors(r, geoMeans = geoMeans)
  dds<-DESeq(dds)
  res <- results(dds)
  res.p<-res$padj
  names(res.p)<-res@rownames
  res.p}

test.resp<-deseq.res(r1)

deseqIndics<-function(ps){
  require(phyloseq)
  require(DESeq2)
  r1<-subset_samples(ps, Factor=="one"|Factor=="two")
  r2<-subset_samples(ps, Factor=="one"|Factor=="three")
  r3<-subset_samples(ps, Factor=="one"|Factor=="four")
  r4<-subset_samples(ps, Factor=="one"|Factor=="five")
  r5<-subset_samples(ps, Factor=="one"|Factor=="six")
  tab<-ldply(list(r1,r2,r3,r4,r5), deseq.res)
  tab<-t(tab)
  tab[tab > 0.05]<-NA
  tab[tab < 0.05]<-1
  tab[is.na(tab)]<-0
  #tab[tab > 0.05]<-0
  colnames(tab)<-c("OneVTwo", "OneVThree", "OneVFour", "OneVFive", "OneVSix")
  tab
}

Deseq.ind.raw<-deseqIndics(model4.raw)
Deseq.ind.eRare<-deseqIndics(model4.eRare)
Deseq.ind.pRare<-deseqIndics(model4.pRare)
Deseq.ind.scaled<-deseqIndics(model4.scaled)
```

```{R}
library(vegan)
library(indicspecies)

indicspp<-function(ps){
  require(phyloseq)
  require(indicspecies)
  #ps<-filter_taxa(ps, function(x) sum(x)>0, T)
  p<-as.data.frame(as.matrix(t(otu_table(ps))))
  e<-sample_data(ps)$Factor
  
  m<-multipatt(p, e, control=how(nperm=999), duleg=TRUE)
  m.s<-m$sign
  m.s[is.na(m.s$p.value), 9]<-1.000
  m.s[m.s$p.value>0.05,1:6]<-0
  m.s[is.na(m.s)]<-0
  m.s
  }
indicsummary<-function(ps){
  require(phyloseq)
  require(indicspecies)
  #ps<-filter_taxa(ps, function(x) sum(x)>0, T)
  p<-as.data.frame(as.matrix(t(otu_table(ps))))
  e<-sample_data(ps)$Factor
  
  m<-multipatt(p, e, control=how(nperm=999))
  summary(m)
  }
model3.raw.indicspp<-indicspp(model3.raw)
model3.erare.indicspp<-indicspp(model3.eRare)
model3.prare.indicspp<-indicspp(model3.pRare)
model3.scaled.indicspp<-indicspp(model3.scaled)

model4.raw.indicspp<-indicspp(model4.raw)
model4.indicspp<-indicspp(model4)
model4.eRare.indicspp<-indicspp(model4.eRare)
model4.pRare.indicspp<-indicspp(model4.pRare)
model4.scaled.indicspp<-indicspp(model4.scaled)

indicsummary(model4.raw)
indicsummary(model4)
indicsummary(model4.eRare)
indicsummary(model4.pRare)
indicsummary(model4.scaled)

rownames(model4.scaled.indicspp[model4.scaled.indicspp$s.one>0, ])
group2.spp$group1
```

```{r}
# anova tests
anova.otu<-as.data.frame(t(as.matrix(otu_table(model4))))
anova.env<-data.frame(as.matrix(sample_data(model4)))
anova.env$F1<-as.numeric(as.character(anova.env$F1))
anova.env$F2<-as.numeric(as.character(anova.env$F2))
anova.env$F3<-as.numeric(as.character(anova.env$F3))
anova.env$F4<-as.numeric(as.character(anova.env$F4))
anova.env$F5<-as.numeric(as.character(anova.env$F5))

anova.dat<-data.frame(anova.otu, anova.env)
anova.out<-aov(spp663~Factor+F1+F2+F3+F4+F5, data=anova.dat)
lm.out<-lm(spp663~Factor+F1+F2+F3+F4+F5, data=anova.dat)
summ<-summary(anova.out)
summ.lm<-summary(lm.out)
tukey.out<-TukeyHSD(anova.out)

anova.output<-colnames(anova.otu)
names(anova.output)<-colnames(anova.otu)

testaov<-apply(anova.otu, 2, function(x) {
  l1=summary(aov(x~anova.env$Factor))
  l2=TukeyHSD(aov(x~anova.env$Factor))
  a=l2
  b=l1[[1]]$`Pr(>F)`
  return(list("Tukey"=a,"P"=b))})


test.summary<-c(1:length(aov))
for(i in 1:length (testaov)){
  if(testaov[[i]]$P[1]<0.05){test.summary[i]<-1}
  if(testaov[[i]]$P[1]>0.05){test.summary[i]<-0}
  names(test.summary[i])<-names(testaov)[i]
  }
names(test.summary)<-names(testaov)
test.summary

intersect(group2.spp$group1,group2.spp$group2)
intersect(group2.spp$group1,group2.spp$group3)
intersect(group2.spp$group1,group2.spp$group4)
intersect(group2.spp$group1,group2.spp$group5)
intersect(group2.spp$group1,group2.spp$group6)


# make index of difference explained
# aov -> spp ~ Factor + F1:F2:F3:F4:F5
# for each spp, select percent explained; aggregate var explained overall
# 
lm.test<-function(ps){
anova.otu<-as.data.frame(t(as.matrix(otu_table(ps))))
anova.env<-data.frame(as.matrix(sample_data(ps)))
anova.env$F1<-as.numeric(as.character(anova.env$F1))
anova.env$F2<-as.numeric(as.character(anova.env$F2))
anova.env$F3<-as.numeric(as.character(anova.env$F3))
anova.env$F4<-as.numeric(as.character(anova.env$F4))
anova.env$F5<-as.numeric(as.character(anova.env$F5))

testlm<-apply(anova.otu, 2, function(x) {
  #l1=summary(lm(x~anova.env$Factor+anova.env$F1+anova.env$F2+anova.env$F3+anova.env$F4+anova.env$F5))
  l1=summary(lm(x~anova.env$F1+anova.env$F2+anova.env$F3+anova.env$F4+anova.env$F5))
  return(l1$r.squared)
  })
testlm[is.na(testlm)]<-0
lost<-length(testlm[testlm==0])
out<-list("lm"=testlm, "lost"=lost)
out
} # challenging because the r squared is not necessarily the best indicator...


# ps1 is the reference (model 4)
# ps2 is the test case (model4.raw/model4.eRare/model4.pRare/model4.scaled)
# order matters

SVI<-function(ps1, ps2){
  reference<-lm.test(ps1)
  trt<-lm.test(ps2)
  o<-reference$lm-trt$lm
  o
}

# NEW SVI ####
SVI2 <-function(ps1.R, ps2.T){
  reference<-as.matrix(as.data.frame(t(as.matrix(otu_table(Delta.sppcount(ps1.R, ps1.R, method=0))))))
  treatment<-as.matrix(as.data.frame(t(as.matrix(otu_table(Delta.sppcount(ps2.T, ps1.R, method=0))))))
  Ci<-sapply(seq.int(dim(reference)[1]), function(i) sum(abs(reference[i,] - treatment[i,])))
  names(Ci)<-rownames(reference)
  Ci
}

svi2.model4.raw<-SVI2(model4, model4.raw)
svi2.model4.eRare<-SVI2(model4, model4.eRare)
svi2.model4.pRare<-SVI2(model4, model4.pRare)
svi2.model4.scaled<-SVI2(model4, model4.scaled)
svi2.model4.deseq.raw<-SVI2(model4, model4.deseq.raw)
SVI2(model4, model4.deseq.eRare)
SVI2(model4, model4.deseq.pRare)
SVI2(model4, model4.deseq.scaled)
svi2.model4.limma.raw<-SVI2(model4, model4.Limma.raw)
SVI2(model4, model4.Limma.eRare)
SVI2(model4, model4.Limma.pRare)
SVI2(model4, model4.Limma.scaled)

sample_sums(prune_taxa("spp127", model4))
sample_sums(prune_taxa("spp127", model4.raw))
sample_sums(prune_taxa("spp127", model4.eRare))
sample_sums(prune_taxa("spp127", model4.pRare))
sample_sums(prune_taxa("spp127", model4.scaled))


# for cannabalism:
benchmark.norm<-function(model){
  val<-data.frame("mean level"=c(rep(20, 50), rep(200, 50), rep(2000, 50)), "var level"=c(rep(c(rep(1, 10), rep(10, 10), rep(100, 10), rep(1000, 10), rep(10000, 10)), 3)), "Index"=c(rep(0, 150)))
  Index=NULL
  
  for(i in 1:nrow(val)){
    seq.depth<-set.seqDepth(val[i,1], val[i,2])
    otu<-make.rarefy2(model, seq.depth)
    
    Ri<-as.matrix(as.data.frame(t(as.matrix(otu_table(Delta.sppcount(model, model, method=0))))))
    Ai<-as.matrix(as.data.frame(t(as.matrix(otu_table(Delta.sppcount(otu, model, method=0))))))
    Ci<-sum(sapply(seq.int(dim(R)[2]), function(i) sum(abs(Ri[,i] - Ai[,i]))))
    
    #val[i,3]<-Ci
    Index[i]<-Ci
  }
  
#val$Index<-Index
val$Index<-Index
val
}

length(SVI(model4, model4.raw))
length(SVI(model4, model4.eRare))
length(SVI(model4, model4.pRare))
length(SVI(model4, model4.scaled))
length(SVI(model4, model4.deseq.raw))
length(SVI(model4, model4.deseq.eRare))
length(SVI(model4, model4.deseq.pRare))
length(SVI(model4, model4.deseq.scaled))
length(SVI(model4, model4.Limma.raw))
length(SVI(model4, model4.Limma.eRare))
length(SVI(model4, model4.Limma.pRare))
length(SVI(model4, model4.Limma.scaled)) # all same length; therefore, can automate making a dataframe out of them

svi1.model4.raw<-SVI(model4, model4.raw)
svi1.model4.eRare<-SVI(model4, model4.eRare)
svi1.model4.pRare<-SVI(model4, model4.pRare)
svi1.model4.scaled<-SVI(model4, model4.scaled)
svi1.model4.deseq.raw<-SVI(model4, model4.deseq.raw)
#length(SVI(model4, model4.deseq.eRare)
#length(SVI(model4, model4.deseq.pRare)
#length(SVI(model4, model4.deseq.scaled)
svi1.model4.limma.raw<-SVI(model4, model4.Limma.raw)
l#ength(SVI(model4, model4.Limma.eRare)
#length(SVI(model4, model4.Limma.pRare)
#length(SVI(model4, model4.Limma.scaled)


# species variance index
S.var1<-data.frame("raw"=svi1.model4.raw,
"eRare"=svi1.model4.eRare,
"pRare"=svi1.model4.pRare,
"scaled"=svi1.model4.scaled,
"deseq"=svi1.model4.deseq.raw,
"Limma"=svi1.model4.limma.raw
)
S.var1$Taxa<-rownames(S.var1)

S.var1a<-reshape2::melt(S.var1, id.vars="Taxa")
ggplot(S.var1a, aes(variable,value))+geom_boxplot()+geom_hline(yintercept=0, linetype="dashed", color="red")+theme_classic()

S.var2<-data.frame("raw"=svi2.model4.raw,
"eRare"=svi2.model4.eRare,
"pRare"=svi2.model4.pRare,
"scaled"=svi2.model4.scaled,
"deseq"=svi2.model4.deseq.raw,
"Limma"=svi2.model4.limma.raw
)
S.var2$Taxa<-rownames(S.var2)

S.var2a<-reshape2::melt(S.var2, id.vars="Taxa")

ggplot(S.var2a, aes(variable,value))+geom_boxplot()+theme_classic()


#SVI(model4, model4.deseq.eRare),
#SVI(model4, model4.deseq.pRare),
#SVI(model4, model4.deseq.scaled),
#SVI(model4, model4.Limma.eRare),
#SVI(model4, model4.Limma.pRare),
#SVI(model4, model4.Limma.scaled)

```

```{r}
model4.lm<-lm.test(model4)
model4.raw.lm<-lm.test(model4.raw)
model4.eRare.lm<-lm.test(model4.eRare)
model4.pRare.lm<-lm.test(model4.pRare)
model4.scaled.lm<-lm.test(model4.scaled)
model4.deseq.raw.lm<-lm.test(model4.deseq.raw)
model4.deseq.eRare.lm<-lm.test(model4.deseq.eRare)
model4.deseq.pRare.lm<-lm.test(model4.deseq.pRare)
model4.deseq.scaled.lm<-lm.test(model4.deseq.scaled)
model4.limma.raw.lm<-lm.test(model4.Limma.raw)
model4.limma.eRare.lm<-lm.test(model4.Limma.eRare)
model4.limma.pRare.lm<-lm.test(model4.Limma.pRare)
model4.limma.scaled.lm<-lm.test(model4.Limma.scaled)


model4.lm$lost
model4.raw.lm$lost
model4.eRare.lm$lost
model4.pRare.lm$lost
model4.scaled.lm$lost
model4.deseq.raw.lm$lost

length(model4.limma.raw.lm$lm)
model4.limma.raw.lm$lost
data.frame(model4.lm$lm, model4.raw.lm$lm, model4.deseq.raw.lm$lm, model4.limma.raw.lm$lm)

sum(model4.lm$lm-model4.scaled.lm$lm)


names(test.summary)<-names(testaov)
test.summary

```

```{r}


# make table of r squared for each species between two otu tables. Problematic because the predictive value of organisms that occure only in one site is 100% even if the predicted abundance is very far off.
spp.corr<-function(ps1, ps2){
anova.otu1<-as.data.frame(t(as.matrix(otu_table(ps1))))
anova.otu2<-as.data.frame(t(as.matrix(otu_table(ps2))))
if(!identical(colnames(ps1), colnames(ps2))) {print("Species do not match, check taxa_names()")}
out<-list(colnames)
testlm<-apply(anova.otu1, 2, function(x) {
  #l1=summary(lm(x~anova.env$Factor+anova.env$F1+anova.env$F2+anova.env$F3+anova.env$F4+anova.env$F5))
  l1=summary(lm(x~anova.env$F1+anova.env$F2+anova.env$F3+anova.env$F4+anova.env$F5))
  return(l1$r.squared)
  })
testlm[is.na(testlm)]<-0
lost<-length(testlm[testlm==0])
out<-list("lm"=testlm, "lost"=lost)
out
}

# make the difference between predicted values and actual normalized values of species abundance for each normalization method
# index using sum of difference for each method between predicted and actual abundance for each spp and all spp

# normalize each species count by the relative abundance of that species at each site compared to it's own abundance at each other site. This is a pecursor for an analysis to determine how well each pre-processing and normalization method approximates the actual magnitude and direction of changes in species abundance
Delta.sppcount<-function(ps,ref, method=0){
  tab<-as.data.frame(as.matrix(otu_table(ref)))
  tab[]<-0
  env<-sample_data(ref)
  tab<-phyloseq(otu_table(tab, taxa_are_rows = TRUE), sample_data(env))
  #make phyloseq object, subset phyloseq then merge second phyloseq.
  
  #merge_phyloseq()
  out<-as.data.frame(t(as.matrix(otu_table(ps))))
  out1<-as.data.frame(t(as.matrix(otu_table(ps))))
  if(method==1){
    out<-exp(out)
    out<-sapply(seq.int(dim(out)[2]), function(i) out[,i]/sum(out[,i]))
    out[is.nan(out)]<-0
    rownames(out)<-rownames(out1)
    colnames(out)<-colnames(out1)
    ps<-otu_table(out, taxa_are_rows = F)
    ps<-merge_phyloseq(ps, tab)
    ps
  } else {
    out<-sapply(seq.int(dim(out)[2]), function(i) out[,i]/sum(out[,i]))
    out[is.nan(out)]<-0
    rownames(out)<-rownames(out1)
    colnames(out)<-colnames(out1)
    ps<-otu_table(out, taxa_are_rows = F)
    ps<-merge_phyloseq(ps, tab)
    ps
  }
}


# this function estimates the difference in magnitude estimation of species abundance when compared to the actual changes in species abundance in the environment.
Dspp.index<-function(l.tab, R){ R<-as.matrix(R)
lapply(l.tab, function(a) {
   A<-as.matrix(a)
  sum(sapply(seq.int(dim(R)[2]), function(i) sum(abs(R[,i] - A[,i]))))}) # should to check operation properly!! check that they are identical, check that they go line by line...
 }

  
```

```{r}

# model workflow
anova.otu1<-as.data.frame(t(as.matrix(otu_table(model4))))
anova.otu2<-as.data.frame(t(as.matrix(otu_table(model4.deseq.raw))))
anova.otu3<-as.data.frame(t(as.matrix(otu_table(model4.scaled))))
anova.otu4<-as.data.frame(t(as.matrix(otu_table(model4.raw))))

A <- as.matrix(anova.otu1)
B <- as.matrix(anova.otu2)
C <- as.matrix(anova.otu3)
D <- as.matrix(anova.otu4)
df.test<-data.frame(sapply(seq.int(dim(A)[2]), function(i) cor(A[,i], B[,i])), sapply(seq.int(dim(A)[2]), function(i) cor(A[,i], C[,i])), sapply(seq.int(dim(A)[2]), function(i) cor(A[,i], D[,i])))

df.test[is.na(df.test)]<-0
sum(df.test$sapply.seq.int.dim.A..2....function.i..cor.A...i...B...i...)
sum(df.test$sapply.seq.int.dim.A..2....function.i..cor.A...i...C...i...)
sum(df.test$sapply.seq.int.dim.A..2....function.i..cor.A...i...D...i...)
 
!identical(colnames(anova.otu1),colnames(anova.otu1))

### need to somehow put place holder for zeros for samples that have been dropped in the rarefied/subsampled samples
### test against 1  


DSpp.model4.ref<-as.data.frame(t(as.matrix(otu_table(Delta.sppcount(model4, method=0)))))
DSpp.model4.raw<-as.data.frame(t(as.matrix(otu_table(Delta.sppcount(model4.raw, method=0)))))
DSpp.model4.eRare<-as.data.frame(t(as.matrix(otu_table(Delta.sppcount(model4.eRare, method=0)))))
DSpp.model4.pRare<-as.data.frame(t(as.matrix(otu_table(Delta.sppcount(model4.pRare, method=0)))))
DSpp.model4.scaled<-as.data.frame(t(as.matrix(otu_table(Delta.sppcount(model4.scaled, method=0)))))
model4list<-list("DSpp.model4.raw"=DSpp.model4.raw,"DSpp.model4.eRare"=DSpp.model4.eRare,"DSpp.model4.pRare"=DSpp.model4.pRare,"DSpp.model4.scaled"=DSpp.model4.scaled)

DSpp.model4.ref<-as.data.frame(t(as.matrix(otu_table(Delta.sppcount(model4.deseq.raw, method=1)))))
Null.ref<-as.data.frame(matrix(data=1, nrow=193,ncol=30))
model4list<-list(DSpp.model4.raw,DSpp.model4.eRare,DSpp.model4.pRare,DSpp.model4.scaled,Null.ref)


rownames(as.data.frame(t(as.matrix(otu_table(model4.eRare)))))
rownames(as.data.frame(t(as.matrix(otu_table(model4.pRare)))))


A <- as.matrix(anova.otu1)
B <- as.matrix(anova.otu2)
C <- as.matrix(anova.otu3)
D <- as.matrix(anova.otu4)

sum(sapply(seq.int(dim(A)[2]), function(i) sum(abs(A[,i] - B[,i]))))
sum(sapply(seq.int(dim(A)[2]), function(i) sum(abs(A[,i] - C[,i]))))
sum(sapply(seq.int(dim(A)[2]), function(i) sum(abs(A[,i] - D[,i]))))
sum(sapply(seq.int(dim(A)[2]), function(i) sum(abs(A[,i] - 1))))

test.DsppIndex<-Dspp.index(model4list, R=DSpp.model4.ref)


```


```{r}

make.PERMANOVA<-function(ps){
  require(vegan)
  require(phyloseq)
  ps<-filter_taxa(ps, function(x) sum(x)>0, T)
  x<-as.data.frame(t(as.matrix(otu_table(ps))))
  y<-data.frame(as.matrix(sample_data(ps)))
  y$F1<-as.numeric(as.character(y$F1))
  y$F2<-as.numeric(as.character(y$F2))
  y$F3<-as.numeric(as.character(y$F3))
  y$F4<-as.numeric(as.character(y$F4))
  y$F5<-as.numeric(as.character(y$F5))
  data.frame(x,y)
  a<-adonis(x~Factor2+F1+F2+F3+F4+F5, data=y)
  a
}

```

```{r}
# framework for benchmarking:
# for each test/normalization combination, make object with:


# indicators by group [table of 0 or 1 or -1]
# input objects as a list
# produce a summary table of each metric

# then make an ouput table with percent correct by object

df<-ldply()
```

Now let's benchmark this community:
```{R}
# here ps is a phyloseq object that represents true abundance before subsampling/sequence simmulation
plotserieslines <- function(yvar){
    ggplot(test.tab, aes_(x=~levels,y=as.name(yvar))) +
        geom_boxplot()+ggtitle(as.name(yvar))
        #facet_wrap(~Month)
}

model4
test.tab<-as.data.frame(as.matrix(t(otu_table(model4))))
test.tab$levels<-test.env$Factor# is this the original before subsampling?
test.env<-sample_data(model4.scaled)

par(mfrow=c(20,16))
# from: https://rstudio-pubs-static.s3.amazonaws.com/232094_a8de2e47b78b4556a108e58c808b37cb.html

lapply(names(test.tab), plotserieslines)





```

```{R}
# here ps is a phyloseq object that represents true abundance before subsampling/sequence simmulation
model3
test.tab<-as.data.frame(as.matrix(t(otu_table(model3))))
test.tab$levels<-test.env$Factor# is this the original before subsampling?
test.env<-sample_data(model3.scaled)

par(mfrow=c(20,16))
# from: https://rstudio-pubs-static.s3.amazonaws.com/232094_a8de2e47b78b4556a108e58c808b37cb.html
lapply(names(test.tab), plotserieslines)

```

Community ecology approach:

```{r}



```

Environmental correlation/permanova tests
```{R}
# Raw counts Model 3

make.PERMANOVA<-function(ps){
  require(vegan)
  require(phyloseq)
  ps<-filter_taxa(ps, function(x) sum(x)>0, T)
  x<-as.data.frame(t(as.matrix(otu_table(ps))))
  y<-data.frame(as.matrix(sample_data(ps)))
  y$F1<-as.numeric(as.character(y$F1))
  y$F2<-as.numeric(as.character(y$F2))
  y$F3<-as.numeric(as.character(y$F3))
  y$F4<-as.numeric(as.character(y$F4))
  y$F5<-as.numeric(as.character(y$F5))
  a<-adonis(x~Factor2+F1+F2+F3+F4+F5, data=y)
  a
}

```

multipatt expects that species distributions will be patchy, and that species exclusion due to certain experimental conditions is likely. Therefore it is better at capturing experimentally driven patterns in species occurence. 

Because the tests operate differently, the keys need to be built using different structures. The differential abundance analysis are based off of case-control paradigm where factor 1 is a reference and the question is whether the species abundance at factor level 2 is different than at factor level 1. Whereas the inidcator species deals with occurence patterns and asks whether species is more likely to be found at factor level 1 or at factor level 2.  Build the keys:
```{r}
# for differential abundance; make reference
library(phyloseq)
ref<-merge_samples(model4, "Factor", fun = mean)
ref<-as.data.frame(as.matrix(t(otu_table(ref))))
ref.DA<-data.frame("OneVTwo"=ref$one-ref$two, "OneVThree"=ref$one-ref$three, "OneVFour"=ref$one-ref$four, "OneVFive"=ref$one-ref$five, "OneVSix"=ref$one-ref$six)
rownames(ref.DA)<-rownames(ref)

Deseq.ind

#transform indicator spp:
t.model4.raw.indicspp<-data.frame("OneVTwo"=model4.raw.indicspp$s.one+model4.raw.indicspp$s.two, "OneVThree"=model4.raw.indicspp$s.one+model4.raw.indicspp$s.three, "OneVFour"=model4.raw.indicspp$s.one+model4.raw.indicspp$s.four, "OneVFive"=model4.raw.indicspp$s.one+model4.raw.indicspp$s.five, "OneVSix"=model4.raw.indicspp$s.one+model4.raw.indicspp$s.six)
rownames(t.model4.raw.indicspp)<-rownames(model4.raw.indicspp)

t.model4.eRare.indicspp<-data.frame("OneVTwo"=model4.eRare.indicspp$s.one+model4.eRare.indicspp$s.two, "OneVThree"=model4.eRare.indicspp$s.one+model4.eRare.indicspp$s.three, "OneVFour"=model4.eRare.indicspp$s.one+model4.eRare.indicspp$s.four, "OneVFive"=model4.eRare.indicspp$s.one+model4.eRare.indicspp$s.five, "OneVSix"=model4.eRare.indicspp$s.one+model4.eRare.indicspp$s.six)
rownames(t.model4.eRare.indicspp)<-rownames(model4.eRare.indicspp)

t.model4.pRare.indicspp<-data.frame("OneVTwo"=model4.pRare.indicspp$s.one+model4.pRare.indicspp$s.two, "OneVThree"=model4.pRare.indicspp$s.one+model4.pRare.indicspp$s.three, "OneVFour"=model4.pRare.indicspp$s.one+model4.pRare.indicspp$s.four, "OneVFive"=model4.pRare.indicspp$s.one+model4.pRare.indicspp$s.five, "OneVSix"=model4.pRare.indicspp$s.one+model4.pRare.indicspp$s.six)
rownames(t.model4.pRare.indicspp)<-rownames(model4.pRare.indicspp)


t.model4.scaled.indicspp<-data.frame("OneVTwo"=model4.scaled.indicspp$s.one+model4.scaled.indicspp$s.two, "OneVThree"=model4.scaled.indicspp$s.one+model4.scaled.indicspp$s.three, "OneVFour"=model4.scaled.indicspp$s.one+model4.scaled.indicspp$s.four, "OneVFive"=model4.scaled.indicspp$s.one+model4.scaled.indicspp$s.five, "OneVSix"=model4.scaled.indicspp$s.one+model4.scaled.indicspp$s.six)
rownames(t.model4.scaled.indicspp)<-rownames(model4.scaled.indicspp)


library(data.table)
m.Deseq.ind<-reshape2::melt(Deseq.ind, id.vars=rownames(Deseq.ind))
m.ref.DA<-reshape2::melt(as.matrix(ref.DA), id.vars=rownames(ref.DA))
mt.model4.raw.indicspp<-reshape2::melt(as.matrix(t.model4.raw.indicspp), id.vars=rownames(t.model4.raw.indicspp))

# sanity check, should be TRUE:
identical(m.Deseq.ind$Var2, m.ref.DA$Var2)
identical(m.Deseq.ind$Var1, m.ref.DA$Var1)
identical(mt.model4.raw.indicspp$Var1, m.ref.DA$Var1)
identical(mt.model4.raw.indicspp$Var2, m.ref.DA$Var2)

plot.dat<-data.frame("SpeciesID"=m.ref.DA$Var1, "Comparison"=m.ref.DA$Var2, "Difference"=m.ref.DA$value, "Deseq"=m.Deseq.ind$value, "Indicspp"=mt.model4.raw.indicspp$value)

ggplot(plot.dat[plot.dat$Difference<100 & plot.dat$Difference>-100,], aes(x=Difference, y=Deseq, color=as.factor(Indicspp),position_dodge(0.5)))+
  geom_point(alpha=0.1)
  #color_

ggplot(plot.dat, aes(x=Difference, y=Deseq, color=as.factor(Indicspp),position_dodge(0.5)))+
  geom_point(alpha=0.1)

  ggplot(plot.dat[plot.dat$Difference<100 & plot.dat$Difference>-100,], aes(x=Difference, y=Indicspp, color=as.factor(Deseq),position_dodge(0.5)))+
  geom_point()

  
  # for indicator species
# "Correct" pattern determined by group lists and species equations in the reference community


```

```{r}

m.Deseq.ind.raw<-reshape2::melt(Deseq.ind.raw, id.vars=rownames(Deseq.ind.raw))
m.Deseq.ind.eRare<-reshape2::melt(Deseq.ind.eRare, id.vars=rownames(Deseq.ind.eRare))
m.Deseq.ind.pRare<-reshape2::melt(Deseq.ind.eRare, id.vars=rownames(Deseq.ind.pRare))
m.Deseq.ind.scaled<-reshape2::melt(Deseq.ind.scaled, id.vars=rownames(Deseq.ind.scaled))
#m.ref.DA<-reshape2::melt(as.matrix(ref.DA), id.vars=rownames(ref.DA))
```

```{r}
mt.model4.raw.indicspp<-reshape2::melt(as.matrix(t.model4.raw.indicspp), id.vars=rownames(t.model4.raw.indicspp))
mt.model4.eRare.indicspp<-reshape2::melt(as.matrix(t.model4.eRare.indicspp), id.vars=rownames(t.model4.eRare.indicspp))
mt.model4.pRare.indicspp<-reshape2::melt(as.matrix(t.model4.pRare.indicspp), id.vars=rownames(t.model4.pRare.indicspp))
mt.model4.scaled.indicspp<-reshape2::melt(as.matrix(t.model4.scaled.indicspp), id.vars=rownames(t.model4.scaled.indicspp))

```

```{r}
# sanity check, should be TRUE:
identical(m.Deseq.ind.scaled$Var2, m.ref.DA$Var2)
identical(m.Deseq.ind.scaled$Var1, m.ref.DA$Var1)
identical(mt.model4.scaled.indicspp$Var1, m.ref.DA$Var1)
identical(mt.model4.scaled.indicspp$Var2, m.ref.DA$Var2)

model4.plot.dat<-data.frame("SpeciesID"=m.ref.DA$Var1, "Comparison"=m.ref.DA$Var2, "Difference"=m.ref.DA$value, "Deseq.raw"=m.Deseq.ind.raw$value,"Deseq.eRare"=m.Deseq.ind.eRare$value,"Deseq.pRare"=m.Deseq.ind.pRare$value,"Deseq.scaled"=m.Deseq.ind.scaled$value, "Indicspp.raw"=mt.model4.raw.indicspp$value,"Indicspp.eRare"=mt.model4.eRare.indicspp$value,"Indicspp.pRare"=mt.model4.pRare.indicspp$value,"Indicspp.scaled"=mt.model4.scaled.indicspp$value)

ggplot(plot.dat.scaled, aes(x=Difference, y=Deseq, color=as.factor(Indicspp),position_dodge(0.5)))+
  geom_point(alpha=0.1)

ggplot(plot.dat.scaled[plot.dat.scaled$Difference<1000 & plot.dat.scaled$Difference>-1000,], aes(x=Difference, y=Deseq, color=as.factor(Indicspp),position_dodge(0.5)))+
  geom_point(alpha=0.1)
  
#ggplot(plot.dat[plot.dat$Difference<100 & plot.dat$Difference>-100,], aes(x=Difference, y=Indicspp, color=as.factor(Deseq),position_dodge(0.5)))+
 # geom_point()
# for indicator species
# "Correct" pattern determined by group lists and species equations in the reference community


```

```{r}
# indicspp raw vs erare
par(mfrow=c(1,2))
ggplot(model4.plot.dat, aes(x=Difference, y=Indicspp.raw, color=as.factor(Indicspp.eRare)))+
  geom_point(alpha=0.2, position="jitter")+theme_classic()

ggplot(model4.plot.dat, aes(x=Difference, y=Indicspp.eRare, color=as.factor(Indicspp.raw)))+
  geom_point(alpha=0.2, position="jitter")+theme_classic()

ggplot(model4.plot.dat, aes(x=Indicspp.eRare, y=Indicspp.raw, color=Difference))+
  geom_point(position="jitter")+theme_classic()+scale_color_gradient2(midpoint = 0, low = "blue", mid = "white",high = "red", space = "Lab" )
```

```{r}
# indicspp raw vs prare
ggplot(model4.plot.dat, aes(x=Difference, y=Indicspp.raw, color=as.factor(Indicspp.pRare)))+
  geom_point(alpha=0.2, position="jitter")+theme_classic()
ggplot(model4.plot.dat, aes(x=Difference, y=Indicspp.eRare, color=as.factor(Indicspp.raw)))+
  geom_point(alpha=0.2, position="jitter")+theme_classic()


```

```{r}
# indicspp raw vs scaled
ggplot(model4.plot.dat, aes(x=Difference, y=Indicspp.raw, color=as.factor(Indicspp.scaled)))+
  geom_point(alpha=0.2, position="jitter")+theme_classic()

ggplot(model4.plot.dat, aes(x=Difference, y=Indicspp.scaled, color=as.factor(Indicspp.raw)))+
  geom_point(alpha=0.2, position="jitter")+theme_classic()
```

```{r}
# Deseq raw vs erare
ggplot(model4.plot.dat, aes(x=Difference, y=Deseq.raw, color=as.factor(Deseq.eRare)))+
  geom_point(alpha=0.2, position="jitter")+theme_classic()

ggplot(model4.plot.dat, aes(x=Difference, y=Deseq.eRare, color=as.factor(Deseq.raw)))+
  geom_point(alpha=0.2, position="jitter")+theme_classic()

```

```{r}
# Deseq raw vs prare
ggplot(model4.plot.dat, aes(x=Difference, y=Deseq.raw, color=as.factor(Deseq.pRare)))+
  geom_point(alpha=0.2, position="jitter")+theme_classic()

ggplot(model4.plot.dat, aes(x=Difference, y=Deseq.pRare, color=as.factor(Deseq.raw)))+
  geom_point(alpha=0.2, position="jitter")+theme_classic()

```

```{r}
# Deseq raw vs scaled

ggplot(model4.plot.dat, aes(x=Difference, y=Deseq.raw, color=as.factor(Deseq.scaled)))+
  geom_point(alpha=0.2, position="jitter")+theme_classic()

ggplot(model4.plot.dat, aes(x=Difference, y=Deseq.scaled, color=as.factor(Deseq.raw)))+
  geom_point(alpha=0.2, position="jitter")+theme_classic()
```

```{r}
# Deseq raw vs indicspp raw
ggplot(model4.plot.dat, aes(x=Difference, y=Deseq.raw, color=as.factor(Indicspp.raw)))+
  geom_point(alpha=0.2, position="jitter")+theme_classic()

ggplot(model4.plot.dat, aes(x=Difference, y=Indicspp.raw, color=as.factor(Deseq.raw)))+
  geom_point(alpha=0.2, position="jitter")+theme_classic()

```

```{r}
# Deseq raw vs indicspp scaled
ggplot(model4.plot.dat, aes(x=Difference, y=Deseq.raw, color=as.factor(Indicspp.scaled)))+
  geom_point(alpha=0.2, position="jitter")+theme_classic()

ggplot(model4.plot.dat, aes(x=Difference, y=Indicspp.scaled, color=as.factor(Deseq.raw)))+
  geom_point(alpha=0.2, position="jitter")+theme_classic()
```

```{r}
# Deseq scaled vs indicspp raw
ggplot(model4.plot.dat, aes(x=Difference, y=Deseq.scaled, color=as.factor(Indicspp.raw)))+
  geom_point(alpha=0.2, position="jitter")+theme_classic()

ggplot(model4.plot.dat, aes(x=Difference, y=Indicspp.raw, color=as.factor(Deseq.scaled)))+
  geom_point(alpha=0.2, position="jitter")+theme_classic()
```

```{r}
# Deseq scaled vs indicspp scaled
ggplot(model4.plot.dat, aes(x=Difference, y=Deseq.scaled, color=as.factor(Indicspp.scaled)))+
  geom_point(alpha=0.2, position="jitter")+theme_classic()

ggplot(model4.plot.dat, aes(x=Difference, y=Indicspp.scaled, color=as.factor(Deseq.scaled)))+
  geom_point(alpha=0.2, position="jitter")+theme_classic()

```

```{r}
# Limma raw vs erare
```

```{r}
# Limma raw vs prare
```

```{r}
# Limma raw vs scaled
```


Beta diversity analysis:
```{R}

deseq.plot.dat<-data.frame("SpeciesID"=m.ref.DA$Var1, "Comparison"=m.ref.DA$Var2, "Difference"=m.ref.DA$value, "Deseq_scaled"=m.Deseq.ind.scaled$value, "Deseq_raw"=m.Deseq.ind$value)

ggplot(deseq.plot.dat, aes(x=Difference, y=Deseq_raw, color=as.factor(Deseq_scaled),position_dodge(0.5)))+
  geom_point(alpha=0.1)

ggplot(deseq.plot.dat[deseq.plot.dat$Difference<100 & deseq.plot.dat$Difference>-100,], aes(x=Difference, y=Deseq_raw, color=as.factor(Deseq_scaled),position_dodge(0.5)))+
  geom_point(alpha=0.1)
```

```{r}

# Raw counts Model 3
permanova.model3Raw<-make.PERMANOVA(model3.raw)
permanova.model3Raw
```

```{R}
# Even Rarefied counts Model 3
permanova.model3eRare<-make.PERMANOVA(model3.eRare)
permanova.model3eRare
```

```{R}
# Proportional Rarefied Counts Model 3
permanova.model3pRare<-make.PERMANOVA(model3.pRare)
permanova.model3pRare
```

```{R}
# Scaled Counts Model 3
permanova.model3scaled<-make.PERMANOVA(model3.scaled)
permanova.model3scaled
```

```{R}
# DESeqVST Counts Model 3
permanova.model3DeseqVST<-make.PERMANOVA(model3.DeseqVST)
permanova.model3DeseqVST
```

```{R}
# LimmaVST Counts Model 3
permanova.model3limmaVST<-make.PERMANOVA(model3.limmaVST)
permanova.model3limmaVST
```

Table of model 3 R^2
```{R}
Table3<-data.frame("raw"=permanova.model3Raw$aov.tab$R2, "eRare"=permanova.model3eRare$aov.tab$R2, "pRare"=permanova.model3pRare$aov.tab$R2, "scaled"=permanova.model3scaled$aov.tab$R2, "limmaVST"=permanova.model3limmaVST$aov.tab$R2, "DeseqVST"=permanova.model3DeseqVST$aov.tab$R2)
rownames(Table3)<-rownames(permanova.model3Raw$aov.tab)
Table3

```


```{R}
# Raw counts Model 4
permanova.model4raw<-make.PERMANOVA(model4.raw)
permanova.model4raw

```

```{R}
# Even Rarefied counts Model 4
permanova.model4eRare<-make.PERMANOVA(model4.eRare)
permanova.model4eRare

```

```{R}
# Proportional Rarefied Counts Model 4
permanova.model4pRare<-make.PERMANOVA(model4.pRare)
permanova.model4pRare

```

```{R}
# Scaled Counts Model 4
permanova.model4scaled<-make.PERMANOVA(model4.scaled)
permanova.model4scaled

```

```{R}
# DESeqVST Counts Model 4
model4.deseq.raw2<-model4.deseq.raw
z<-as.data.frame(as.matrix(otu_table(model4.deseq.raw)))
z<-z+7
otu_table(model4.deseq.raw2)<-otu_table(z,taxa_are_rows = T)

permanova.model4deseqVST<-make.PERMANOVA(model4.deseq.raw2)
permanova.model4deseqVST
```

```{R}
# LimmaVST Counts Model 4
permanova.model4LimmaVST<-make.PERMANOVA(model4.Limma.raw)
permanova.model4LimmaVST
```
What is the effect of increasing the variation of sequencing depth? 
```{R}
Table4<-data.frame("raw"=permanova.model4raw$aov.tab$R2, "eRare"=permanova.model4eRare$aov.tab$R2, "pRare"=permanova.model4pRare$aov.tab$R2, "scaled"=permanova.model4scaled$aov.tab$R2, "limmaVST"=permanova.model4LimmaVST$aov.tab$R2, "deseqVST"=permanova.model4deseqVST$aov.tab$R2)
rownames(Table4)<-rownames(permanova.model4raw$aov.tab)
Table4

```


```{r}

# here ps is a phyloseq object that represents true abundance before subsampling/sequence simmulation
model4
test.tab<-as.data.frame(as.matrix(t(otu_table(model4))))
test.tab$levels<-test.env$Factor# is this the original before subsampling?
test.env<-sample_data(model4.scaled)

par(mfrow=c(20,16))
# from: https://rstudio-pubs-static.s3.amazonaws.com/232094_a8de2e47b78b4556a108e58c808b37cb.html
plotserieslines <- function(yvar){
    ggplot(test.tab, aes_(x=~levels,y=as.name(yvar))) +
        geom_boxplot()
        #facet_wrap(~Month)
}
lapply(names(test.tab), plotserieslines)

# indicspecies analysis:

library(indicspecies)

pattern1<-multipatt(x, groups, control = how(nperm=999), duleg = T) # duleg = T -> only consider single sites, not combination of sites... could look at all combinations but this would be exhaustive... maybe should also use for modeling?

pattern2<-multipatt(x, groups, control = how(nperm=999))

summary(pattern1)
summary(pattern2)

pattern1$sign # find ones w/ p = NA so that can find which ones are global indicators ...
pattern2$sign

# or do species combinations: 
combinespecies() # very computationally demanding for actual dataset ...


# subset pattern -> select global indicators -> do aov() with correction to determine effects
pattern1.na<-names(pattern1$sign[is.na(pattern1$sign$p.value)])

# subset otu table by pattern1.na then run aov on each species... compile into table

```

Metrics to keep for the real sets:
```{r}
# number of significant indicators that are removed in filtering
# number of significant indicators that are retained after filtering, but do not have log-fold change
# number of significant log-fold change that are not signficant indicators or ANOVA
# number of spp found in anovas that do not have log-fold change
# correlation of species to environmental variables


# make index of endemism: proportion of taxa that are unique to a site
# phylogenetic distance matrix ...

# false discovery rate ####
generate.key<-function(){
  
}

# N is number of replicates
benchmark.FDR<-function(commonN, groupN, singleN, N){
  require(plyr)
  require()
  out<-NULL
}

  # define environment and community
  # commonN = number of common spp
  # groupN = number of spp for each group
  # singleN = number of spp for each site
  # D = mean subsampling depth
  # V = variance around subsampling depth
  pick.tax<-function(commonN, groupN, singleN, D){
    AllSpp<-c(paste0("spp", c(1:700), sep="")) # make a quick list of all species functions
    AllSpp<-lapply(AllSpp, get) # connect function to name
    AllSpp<-unlist(AllSpp)  # format to be read by downstream functions
    names(AllSpp)<-c(paste0("spp", c(1:700)))

    # Define list of 5 species w/ global distribution
    global.spp<-names(sample(AllSpp, commonN, replace=F))

# define list of species w/ regional distribution
    group.spp<-NULL
    group.spp$group1<-names(sample(AllSpp, groupN, replace=F))
    group.spp$group2<-names(sample(AllSpp, groupN, replace=F))
    group.spp$group3<-names(sample(AllSpp, groupN, replace=F))
    group.spp$group4<-names(sample(AllSpp, groupN, replace=F))
    group.spp$group5<-names(sample(AllSpp, groupN, replace=F))
    group.spp$group6<-names(sample(AllSpp, groupN, replace=F))

# define list of species found at each site
    rando.spp<-NULL
    rando.spp$Site1<-unique(c(names(sample(AllSpp, singleN, replace=F)), c(group.spp$group1), global.spp))
    rando.spp$Site2<-unique(c(names(sample(AllSpp, singleN, replace=F)), c(group.spp$group1), global.spp))
    rando.spp$Site3<-unique(c(names(sample(AllSpp, singleN, replace=F)), c(group.spp$group1), global.spp))
    rando.spp$Site4<-unique(c(names(sample(AllSpp, singleN, replace=F)), c(group.spp$group1), global.spp))
    rando.spp$Site5<-unique(c(names(sample(AllSpp, singleN, replace=F)), c(group.spp$group1), global.spp))
    rando.spp$Site6<-unique(c(names(sample(AllSpp, singleN, replace=F)), c(group.spp$group2), global.spp))
    rando.spp$Site7<-unique(c(names(sample(AllSpp, singleN, replace=F)), c(group.spp$group2), global.spp))
    rando.spp$Site8<-unique(c(names(sample(AllSpp, singleN, replace=F)), c(group.spp$group2), global.spp))
    rando.spp$Site9<-unique(c(names(sample(AllSpp, singleN, replace=F)), c(group.spp$group2), global.spp))
    rando.spp$Site10<-unique(c(names(sample(AllSpp,singleN, replace=F)), c(group.spp$group2), global.spp))
    rando.spp$Site11<-unique(c(names(sample(AllSpp, singleN, replace=F)), c(group.spp$group3), global.spp))
    rando.spp$Site12<-unique(c(names(sample(AllSpp, singleN, replace=F)), c(group.spp$group3), global.spp))
    rando.spp$Site13<-unique(c(names(sample(AllSpp, singleN, replace=F)), c(group.spp$group3), global.spp))
    rando.spp$Site14<-unique(c(names(sample(AllSpp, singleN, replace=F)), c(group.spp$group3), global.spp))
    rando.spp$Site15<-unique(c(names(sample(AllSpp, singleN, replace=F)), c(group.spp$group3), global.spp))
    rando.spp$Site16<-unique(c(names(sample(AllSpp, singleN, replace=F)), c(group.spp$group4), global.spp))
    rando.spp$Site17<-unique(c(names(sample(AllSpp, singleN, replace=F)), c(group.spp$group4), global.spp))
    rando.spp$Site18<-unique(c(names(sample(AllSpp, singleN, replace=F)), c(group.spp$group4), global.spp))
    rando.spp$Site19<-unique(c(names(sample(AllSpp, singleN, replace=F)), c(group.spp$group4), global.spp))
    rando.spp$Site20<-unique(c(names(sample(AllSpp, singleN, replace=F)), c(group.spp$group4), global.spp))
    rando.spp$Site21<-unique(c(names(sample(AllSpp, singleN, replace=F)), c(group.spp$group5), global.spp))
    rando.spp$Site22<-unique(c(names(sample(AllSpp, singleN, replace=F)), c(group.spp$group5), global.spp))
    rando.spp$Site23<-unique(c(names(sample(AllSpp, singleN, replace=F)), c(group.spp$group5), global.spp))
    rando.spp$Site24<-unique(c(names(sample(AllSpp, singleN, replace=F)), c(group.spp$group5), global.spp))
    rando.spp$Site25<-unique(c(names(sample(AllSpp, singleN, replace=F)), c(group.spp$group5), global.spp))
    rando.spp$Site26<-unique(c(names(sample(AllSpp, singleN, replace=F)), c(group.spp$group6), global.spp))
    rando.spp$Site27<-unique(c(names(sample(AllSpp, singleN, replace=F)), c(group.spp$group6), global.spp))
    rando.spp$Site28<-unique(c(names(sample(AllSpp, singleN, replace=F)), c(group.spp$group6), global.spp))
    rando.spp$Site29<-unique(c(names(sample(AllSpp, singleN, replace=F)), c(group.spp$group6), global.spp))
    rando.spp$Site30<-unique(c(names(sample(AllSpp, singleN, replace=F)), c(group.spp$group6), global.spp))

# make list of unique species arrays

    library(reshape2)
    f1c1<-c(5,5,5,5,5,5) # number of selections
    f1c2<-c(1,3,10,30,60,15) # mean value of selections
    f1c3<-c(0.5,1,4,10,20,5) # SD of selections
    F1.frame<-mapply(rnorm, f1c1,f1c2,f1c3) # pick Factor 1 value for each site
    F1<-reshape2::melt(F1.frame)

#F2
    f2c1<-c(5,5,5,5,5,5) # number of selections
    f2c2<-c(34,30,10,55,35,60) # mean value of selections
    f2c3<-c(10,10,3,10,1,20) # SD of selections
    F2.frame<-mapply(rnorm, f2c1,f2c2,f2c3) # pick Factor 2 value for each site
    F2<-reshape2::melt(F2.frame)

#F3
    f3c1<-c(5,5,5,5,5,5) # number of selections
    f3c2<-c(1,3,10,15,3,15) # mean value of selections
    f3c3<-c(0.5,1,3,3,1,5) # SD of selections
    F3.frame<-mapply(rnorm, f3c1,f3c2,f3c3) # pick Factor 3 value for each site
    F3<-reshape2::melt(F3.frame)

#F4
    f4c1<-c(5,5,5,5,5,5) # number of selections
    f4c2<-c(1,3,10,15,3,15) # mean value of selections
    f4c3<-c(0.5,0.5,3,3,1,5) # SD of selections
    F4.frame<-mapply(rnorm, f4c1,f4c2,f4c3) # pick Factor 4 value for each site
    F4<-reshape2::melt(F4.frame)

#F5
    f5c1<-c(5,5,5,5,5,5) # number of selections
    f5c2<-c(50,40,30,20,10,15) # mean value of selections
    f5c3<-c(20,10,10,5,3,5) # SD of selections
    F5.frame<-mapply(rnorm, f5c1,f5c2,f5c3) # pick Factor 5 value for each site
    F5<-reshape2::melt(F5.frame)
    Factors<-data.frame(F1$value,F2$value,F3$value,F4$value,F5$value) # combine factors into data table
    
    output<-NULL
    output$spplist<-rando.spp
    output$model<-make.comm2(rando.spp, Factors) # output a phyloseq object... will make a list of phyloseq objects
    sample_data(model)$sums<-sample_sums(model)# add sample sums
    # subsample community
    sample<-set.seqDepth(D,V)
    output$model.raw<-make.rarefy2(model, sample)
    
    # do each of the normalize community processes
    output$sums<-sample_sums(model.raw)
    output$model.eRare<-make.rarefy2(model.raw, min(sums))   ### fill in details !!
    output$model.pRare<-make.rarefy2() 
    output$model.scaled<-make.scaled1(model.raw, , )
    output$model.raw.deseq<-make.deseqVST()
    output$model.scaled.deseq<-make.deseqVST()
    output$model.eRare.deseq<-make.deseqVST()
    output$model.pRare.deseq<-make.deseqVST()
    output$model.raw.limma<-make.limmaVST()
    output$model.eRare.limma<-make.limmaVST()
    output$model.pRare.limma<-make.limmaVST()
    output$model.scaled.limma<-make.limmaVST()
    
    output
}
  

  plotSVI<-function(){}
  plotSVI2<-function(){}
  plotFDR<-function(){}
  plotMDR<-function(){}
  # output SVI index values
  # output SVI2 index values
  # output False discovery rate
  # output missed discovery rate



env<-lapply(,) # make list of env data.frames
Sites<-c(paste0("Site", 1:30))
rownames(Factors)<-Sites
colnames(Factors)<-c("F1","F2","F3","F4","F5")
head(Factors)


# make list of OTU tables ...

# run each normalization on the list of otu tables to generate outputs

# 
  
# plot outputs

# statistics

########### next ... 
  out$plotVSI2<-ggplot()+geom_bar()+theme_classic()
  out$plotVSI<-ggplot()+geom_bar()+theme_classic()
  out$plotFDR<-ggplot()+geom_line()+theme_classic()
  out
}

# true discovery rate ####

# Power to detect #### ( undiscovered true positives )


```

It's not just about the taxa that are driving a pattern. We may want to know which of the rare taxa are responding to changes in the environment, and determine what environmental changes are determining the abundance of these rare organisms. In this case we want a discriminating method that is able to successfully identify taxa that are responding to our experimental conditions.

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.


Build a script to run the following platforms:

DESeq2
Limma Trend
EdgeR
BBSeq 
DSS
BaySeq
ShrinkBayes
PoissonSeq


References:

http://joey711.github.io/waste-not-supplemental/simulation-differential-abundance/simulation-differential-abundance-server.html

https://rachaellappan.github.io/16S-analysis/differential-abundance-with-metagenomeseqs-fitzig.html#normalising-the-data